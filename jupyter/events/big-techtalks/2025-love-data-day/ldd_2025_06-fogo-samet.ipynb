{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24f077bf-867e-42c4-8068-5559f108e35b",
   "metadata": {},
   "source": [
    "<img src=\"https://s0.cptec.inpe.br/webcptec/sites/www/assets/img/logo_cptec.png\" align=\"right\" width=\"64\"/>\n",
    "\n",
    "# <div style=\"text-align: center;\"><span style=\"color:#336699; font-size: 1.2em;\">1º Love Data Day - BIG TechTalks:<br><span style=\"color:#336699; font-style: italic;\">      Usando Dados de Temperatura e STAC Browser em Análise do \"Dia do Fogo em SP\"</span></span></div>\n",
    "<hr style=\"border:2px solid #0077b9;\">\n",
    "\n",
    "<br/>\n",
    "\n",
    "<div style=\"text-align: center;font-size: 90%;\">\n",
    "    Alex de Almeida Fernandes<sup><a href=\"https://orcid.org/0000-0003-1520-5896\"><i class=\"fab fa-lg fa-orcid\" style=\"color: #a6ce39\"></i></a></sup>\n",
    "    <br/><br/>\n",
    "    Divisão de Previsão de Tempo e Clima, Instituto Nacional de Pesquisas Espaciais (INPE)\n",
    "    <br/>\n",
    "    Rodovia Presidente Dutra, km 40, Cachoeira Paulista, SP 12630-000, Brazil\n",
    "    <br/><br/>\n",
    "    Contato: <a href=\"mailto:alex.fernandes@inpe.br\">alex.fernandes@inpe.br</a>\n",
    "    <br/><br/>\n",
    "    Ultíma Atualização: 27 de Maio de 2025\n",
    "</div>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<div style=\"text-align: justify;  margin-left: 25%; margin-right: 25%;\">\n",
    "<b>Resumo.</b> Este Jupyter Notebook é parte do BIG TechTalks, edição especial <i>Love Data Days</i> - Acesso, Visualização e Processamento de dados de temperatura diária do dado SAMeT produzido no INPE. O dado sAMeT consiste na combinação dos dados de superfície das estações em conformidade com o padrão da Organização Meteorológica Mundial e dados numéricos de temperatura. Esta combinação torna a estimativa de temperatura em pontos sem observações mais precisa e permite o uso em locais onde não há observações de superfície nas proximidades. Este Jupyter Notebook apresenta uma visão geral de como utilizar o serviço STAC na linguagem Python para descoberta e acesso aos produtos de dados de sensoriamento remoto disponíveis no catálogo do INPE, além de demonstrar a abertura de arquivos no formato NetCDF e como visualizar os dados de Temperatura.\n",
    "<br/><br/>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f476d888-ed82-40fb-9cae-bd64ac213041",
   "metadata": {},
   "source": [
    "# Dia do Fogo em SP - 23 de Agosto de 2024\n",
    "\n",
    "No dia 23 de agosto de 2024 um evento chamou atenção pública pela ocorrência de diversos focos de fogo iniciando em horários próximos na região norte e oeste do estado de São Paulo.\n",
    "A intenção deste notebook é demonstrar as _condições de fogo_ baseando-se na precipitação ocorrida até 3 meses antes. \n",
    "\n",
    "Os dados de precipitação utilizados será a base do SAMeT/INPE, que combina dados observados em superfície com dados numéricos e interpolações, fornecendo um dado mais preciso do que a simples interpolação ou dados de reanálise.\n",
    "\n",
    "A Temperatura do perído de 2024 será comparada com a média de longo termo iniciada em 2000, dete modo, teremos uma comparação da temperatura média em 24 anos e no perído de ocorrência do evento. Será que a temperatura pode ter ajudado os incêndios neste período?\n",
    "\n",
    "Vamos olhar os dados... De novo..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73163a6a-1070-43e4-bc21-cdd2338b9b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install xarray cfgrib netcdf4\n",
    "#%pip install cartopy\n",
    "#%pip install geopandas\n",
    "#%pip install regionmask\n",
    "#%pip install rioxarray\n",
    "\n",
    "#%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60219ead-b4d4-4f12-b13b-6479d8299ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pystac_client\n",
    "import pystac\n",
    "import itertools\n",
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from pathlib import Path\n",
    "from dateutil.parser import parse\n",
    "import rioxarray  # necessário para clipping com shapefile\n",
    "import geopandas as gpd\n",
    "import zipfile\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "os.environ['PROJ_LIB'] = \"/opt/conda/envs/geospatial/share/proj\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8cf20a-0e0c-4cb1-8d06-7cbc1a7ec411",
   "metadata": {},
   "source": [
    "## 1. Serviço STAC e Coleções\n",
    "\n",
    "Notebook de demonstração de acesso ao catálogo e da coleção de interesse, neste caso o SAMeT com acumulado diário de precipitação em formato _NetCDF_.\n",
    "\n",
    "Boa parte dos produtos de imagem disponibilizados no catálogo de imagens do INPE são disponibilizados de maneira aberta na forma de arquivos otimizados para cloud, o denominado formato Cloud Optimized GeoTIFF (COG). Este formato permite que as aplicações possam utilizar as imagens através da Web com o melhor compromisso possível, incluindo o uso de pirâmide de multi-resolução para aplicações de visualização ou até mesmo a recuperação parcial de porções de uma imagem. O COG e o serviço de análise da BIG/INPE permite várias análises e fecilidades com tal formato, que não será o caso deste notebook. \n",
    "\n",
    "Os produtos de dados podem ser consultados utilizando uma interface de programação de aplicações baseada no padrão aberto SpatioTemporal Asset Catalog (STAC). Esta especificação, criada por organizações e especialistas do setor geoespaciall.\n",
    "\n",
    "Em que:\n",
    "\n",
    "- **Catalog**: É um tipo de objeto que fornece uma estrutura para vincular vários itens ou coleções STAC juntos ou mesmo outros catálogos. Na figura acima, o catálogo é composto de três coleções: Landsat/OLI, CBERS4/WFI e Sentinel-2/MSI.\n",
    "\n",
    "- **Collection:** É uma especialização do catálogo que permite incluir informações adicionais sobre uma determinada coleção espaço-temporal. Uma coleção pode conter informações como o conjunto de bandas espectrais disponíveis das imagens, a extensão geográfica ou área de cobertura das imagens, o período de tempo que compreende a coleção, entre outras informações. Em geral, através da coleção chegamos aos itens dessa coleção.\n",
    "\n",
    "- **Item**: Corresponde à unidade atômica de metadados, fornecendo *links* para os *assets* associados. Um *Item* é descrito através da notação GeoJSON, como uma feição (*feature*) contendo atributos específicos como a coleção a que ele pertence, propriedades temporais, *links* para os *assets* e coleções ou catálogos associados. Na figura acima, um `Item` equivale a uma cena obtida por um satélite em um determinado instante de tempo.\n",
    "\n",
    "- **Asset**: Um *asset* é qualquer recurso geoespacial, como um arquivo de imagem ou arquivo vetorial, contendo informações sobre a supefície da Terra, em um determinado espaço e tempo.\n",
    "\n",
    "\n",
    "A especificação conceitual do STAC permite dois tipos de implementações:\n",
    "\n",
    "- **STAC estático:** Baseada em um conjunto de documentos JSON ligados que podem ser facilmente navegados. Ex: [CBERS na AWS](https://cbers-stac-1-0-0.s3.amazonaws.com/CBERS4/catalog.json).\n",
    "\n",
    "- **STAC dinâmico:** Baseada em uma API RESTful, de modo que a navegação é realizada através de uma API de serviço web que permite realizar consultas utilizando uma linguagem padrão para acessar subconjuntos do catálogo. Ex: [BDC-STAC](https://data.inpe.br/bdc/stac/v1).\n",
    "\n",
    "\n",
    "<br/>\n",
    "<div style=\"text-align: justify;  margin-left: 25%; margin-right: 25%;font-size: 75%; border-style: solid; border-color: #0077b9; border-width: 1px; padding: 5px;\">\n",
    "    <b>Nota:</b> Como parte do aperfeiçoamento dos produtos e serviços disponibilizados pelo INPE à sociedade, encontra-se em desenvolvimento o novo portal <a href=\"https://data.inpe.br/\">https://data.inpe.br/</a>, que faz parte da modernização da infraestrutura de serviços para acesso às imagens de satélites do acervo do instituto. Esse portal foi criado com o intuito de facilitar a pesquisa e obtenção das imagens disponibilizadas gratuitamente. Esse novo serviço tem como base as tecnologias desenvolvidas no projeto Brazil Data Cube, e está ancorado dentro do Programa Base de Informações Georreferenciadas (BIG) do INPE. Para navegar pelas coleções disponibilizadas no serviço STAC do INPE, utilize a instância do [STAC Browser](https://data.inpe.br/stac/browser/).\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cace998d-a738-428a-a1b8-0700119a7723",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PySTAC\n",
    "service = pystac_client.Client.open('https://data.inpe.br/bdc/stac/v1/')\n",
    "service\n",
    "\n",
    "for colecao in service.get_collections():\n",
    "    print(f\"{colecao.id}: {colecao.title}\", end=\"\\n\"*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73650df-74a1-4584-8a2b-80dd548b8964",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = service.get_collection('samet_daily-1')\n",
    "collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6447c6bb-53fa-4ea3-aa71-21cc7c120849",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collection.item_assets['tmax']\n",
    "import itertools\n",
    "\n",
    "item_search = service.search(\n",
    "    collections=['samet_daily-1'],\n",
    "    datetime='2024-05-01/2024-09-01'\n",
    ")\n",
    "\n",
    "print (\"quantidade de itens:\", item_search.matched())\n",
    "\n",
    "samet_list = []\n",
    "for i, item in enumerate(item_search.items()):\n",
    "    print(i, item.assets['tmax'].href, sep='\\t')\n",
    "    samet_list.append(item.assets['tmax'].href)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d48639-577c-42c6-8741-aeb92ba99158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_read_samet_stac(\n",
    "    stac_service: str,\n",
    "    start_date: str,\n",
    "    end_date: str,\n",
    "    collection: str,\n",
    "    var: str,\n",
    "    output_dir: str = \"samet_data\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Busca, baixa e lê dados SAMeT em formato NETCDF de um catálogo STAC,\n",
    "    filtrando por um período de datas.\n",
    "\n",
    "    Args:\n",
    "        stac_catalog_url (str): URL do catálogo/item STAC.\n",
    "        start_date (str): Data inicial (formato ISO ou legível, ex: '2024-01-01').\n",
    "        end_date (str): Data final (formato ISO ou legível, ex: '2024-01-31').\n",
    "        output_dir (str): Pasta onde salvar os arquivos baixados.\n",
    "\n",
    "    Returns:\n",
    "        ds (xarray.Dataset): Dataset contendo os dados lidos.\n",
    "    \"\"\"\n",
    "    # Converte datas para objetos datetime\n",
    "    start_dt = parse(start_date)\n",
    "    end_dt = parse(end_date)\n",
    "\n",
    "    # Cria diretório de saída se não existir\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    downloaded_files = []\n",
    "\n",
    "    if isinstance(service, pystac.Catalog) and stac_service.id == 'INPE':\n",
    "        item_search = service.search(datetime=start_date+'/'+end_date,\n",
    "                             collections=[collection])\n",
    "        for asset in item_search.items():\n",
    "            if asset.assets[var].href.endswith(\".nc\"):\n",
    "                file_url = asset.assets[var].href\n",
    "                filename = Path(file_url).name\n",
    "                file_path = output_path / filename\n",
    "                #print (grib_date)\n",
    "\n",
    "                print(f\"Baixando: {file_url}\")\n",
    "                response = requests.get(file_url, stream=True)\n",
    "                response.raise_for_status()\n",
    "\n",
    "                with open(file_path, \"wb\") as f:\n",
    "                    for chunk in response.iter_content(chunk_size=1024 * 1024):\n",
    "                        if chunk:\n",
    "                            f.write(chunk)\n",
    "\n",
    "                        #print(f\"Arquivo salvo: {file_path}\")\n",
    "                        downloaded_files.append(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"STAC URL deve apontar para um Catálogo ou Item.\")\n",
    "\n",
    "    # Verifica se algum arquivo foi baixado\n",
    "    if not downloaded_files:\n",
    "        raise FileNotFoundError(\"Nenhum arquivo .nc foi encontrado no período especificado.\")\n",
    "\n",
    "    # Lê os arquivos com xarray\n",
    "    print(\"Lendo arquivos com xarray...\")\n",
    "          \n",
    "    # Lê múltiplos arquivos com open_mfdataset, aplicando a função preprocess\n",
    "    ds = xr.open_mfdataset(\n",
    "        downloaded_files,\n",
    "        combine='by_coords')\n",
    "    return ds\n",
    "\n",
    "ds = download_and_read_samet_stac(service, '2024-05-01', '2024-09-01', \n",
    "                                  'samet_daily-1',\n",
    "                                  'tmax',\n",
    "                                  './data-love-days/tmp')\n",
    "ds = ds.sortby('time')\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678ba76f-4ff9-4712-afbd-8e5808e037f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_mlt_tmax_data(\n",
    "    start_date='2024-05-01',\n",
    "    end_date='2024-09-01',\n",
    "    output_dir='mlt_data'\n",
    "):\n",
    "    \"\"\"\n",
    "    Baixa e carrega dados SAMeT de TMAX entre duas datas, usando o formato %d%b no nome do arquivo.\n",
    "\n",
    "    Args:\n",
    "        start_date (str): Data inicial (formato 'YYYY-MM-DD').\n",
    "        end_date (str): Data final (formato 'YYYY-MM-DD').\n",
    "        output_dir (str): Pasta local para salvar os arquivos baixados.\n",
    "\n",
    "    Returns:\n",
    "        ds (xarray.Dataset): Dataset com todos os dados concatenados.\n",
    "    \"\"\"\n",
    "    # Criar pasta de saída se não existir\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(exist_ok=True)\n",
    "\n",
    "    # Gerar lista de datas\n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "\n",
    "    downloaded_files = []\n",
    "\n",
    "    for dt in date_range:\n",
    "        # Formato dia + mês abreviado em minúsculo (ex: '01jun', '31ago')\n",
    "        day_month = dt.strftime('%d%b').lower()  # '29Mar' -> '29mar'\n",
    "\n",
    "        filename = f\"SAMeT_CPTEC_TMAX_00Z{day_month}.nc\"\n",
    "        file_url = f\"https://ftp.cptec.inpe.br/modelos/tempo/SAMeT/CLIMATOLOGY/DAILY_AVERAGE/TMAX/{filename}\"\n",
    "\n",
    "        file_path = output_path / filename\n",
    "\n",
    "        print(f\"Baixando: {file_url}\")\n",
    "\n",
    "        response = requests.get(file_url, stream=True)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            with open(file_path, 'wb') as f:\n",
    "                for chunk in response.iter_content(chunk_size=1024 * 1024):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "            downloaded_files.append(file_path)\n",
    "        else:\n",
    "            print(f\"Arquivo não encontrado: {file_url}\")\n",
    "\n",
    "    if not downloaded_files:\n",
    "        raise FileNotFoundError(\"Nenhum arquivo foi baixado.\")\n",
    "\n",
    "    print(f\"{len(downloaded_files)} arquivos baixados. Carregando com xarray...\")\n",
    "\n",
    "    # Abrir múltiplos arquivos com xarray\n",
    "    ds = xr.open_mfdataset(\n",
    "        downloaded_files,\n",
    "        combine='by_coords'\n",
    "    )\n",
    "\n",
    "    return ds\n",
    "\n",
    "ds_mlt = download_mlt_tmax_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbe19c4-fcdf-4648-b2b0-817d85316911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recortar_dataset_por_regiao(ds, lon_min, lon_max, lat_min, lat_max):\n",
    "    \"\"\"\n",
    "    Recorta o dataset ou dataArray para uma região retangular definida por lat/lon.\n",
    "\n",
    "    Args:\n",
    "        ds (xarray.Dataset or xarray.DataArray): O dataset ou array a ser recortado.\n",
    "        lon_min (float): Longitude mínima da região.\n",
    "        lon_max (float): Longitude máxima da região.\n",
    "        lat_min (float): Latitude mínima da região.\n",
    "        lat_max (float): Latitude máxima da região.\n",
    "\n",
    "    Returns:\n",
    "        xarray.Dataset or xarray.DataArray: Dataset/DataArray recortado para a região especificada.\n",
    "    \"\"\"\n",
    "    # Verifica se as dimensões estão corretas\n",
    "    if 'latitude' in ds.dims and 'longitude' in ds.dims:\n",
    "        # Aplica o recorte\n",
    "        recortado = ds.sel(\n",
    "            longitude=slice(360+lon_min, 360+lon_max),\n",
    "            latitude=slice(lat_min,lat_max)  # Ordem decrescente em latitude é comum em datasets\n",
    "        )\n",
    "    elif 'lat' in ds.dims and 'lon' in ds.dims:\n",
    "        # Aplica o recorte\n",
    "        recortado = ds.sel(\n",
    "            lon=slice(lon_min, lon_max),\n",
    "            lat=slice(lat_min,lat_max)  # Ordem decrescente em latitude é comum em datasets\n",
    "    )\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"O dataset deve conter as dimensões 'latitude' e 'longitude'.\")\n",
    "\n",
    "\n",
    "    return recortado\n",
    "\n",
    "ds_sp = recortar_dataset_por_regiao(ds, -52.9518,-45.2291,-22,-19.2479)\n",
    "ds_sp_mlt = recortar_dataset_por_regiao(ds_mlt, -52.9518,-45.2291,-22,-19.2479)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfb664f-9882-4073-a745-e5781c6b42be",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8396770e-e659-44a1-a070-8d90f329d2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = ds_sp['time']\n",
    "tp = ds_sp['tmax'].mean(axis=[1,2]).values\n",
    "tp_mlt = ds_sp_mlt['ttmax'].mean(axis=[1,2]).values\n",
    "\n",
    "\n",
    "# Calcular diferença\n",
    "diff = tp - tp_mlt\n",
    "\n",
    "# Contador de dias consecutivos e identificação do último dia da sequência\n",
    "consec_days = np.zeros_like(tp, dtype=int)\n",
    "end_of_sequence = np.zeros_like(tp, dtype=bool)\n",
    "\n",
    "contador = 0\n",
    "for i in range(len(tp)):\n",
    "    end_of_sequence[i] = False\n",
    "    if tp[i] > tp_mlt[i]:\n",
    "        contador += 1\n",
    "        # Se for o último dia ou o próximo (i+1) for menor/igual, marca como fim para criar máscara de onde plotar apenas osvalores que antecedem diferenças negativas\n",
    "        if i == len(tp) - 1 or tp[i+1] <= tp_mlt[i+1]:\n",
    "            end_of_sequence[i] = True\n",
    "    else:\n",
    "        contador = 0\n",
    "    consec_days[i] = contador\n",
    "\n",
    "# Plot principal\n",
    "fig, ax1 = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# Linhas principais\n",
    "ax1.plot(dt, tp, color='blue', label='Temperatura Estimada (T)', linewidth=2)\n",
    "ax1.plot(dt, tp_mlt, color='red', label='Média de Longo Termo - MLT (O)', linewidth=2)\n",
    "\n",
    "# Barras: diferença no final de cada sequência\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "bars = ax2.bar(dt, diff, width=1.0, color='orangered', alpha=0.3,\n",
    "               label='Dias consecutivos acima da MLT', edgecolor='black')\n",
    "\n",
    "ax1.set_ylim(20, 40) \n",
    "ax2.set_ylim(-12, 10) \n",
    "\n",
    "# Adicionar texto com número de dias acima de cada barra\n",
    "i = 0\n",
    "for bar, count in zip(bars, consec_days):\n",
    "    height = bar.get_height()\n",
    "    if end_of_sequence[i]:\n",
    "        ax2.text(\n",
    "            bar.get_x() + bar.get_width()/2.+0.3,  # Centraliza o texto\n",
    "            height + 0.2,                      # Um pouco acima da barra\n",
    "            f'{count} dia{\"s\" if count > 1 else \"\"}',\n",
    "            ha='center',\n",
    "            va='bottom',\n",
    "            fontsize=10,\n",
    "            rotation='vertical'\n",
    "        )\n",
    "    i = i + 1\n",
    "\n",
    "# Formatação do eixo X\n",
    "dates = pd.to_datetime(dt)\n",
    "formatted_labels = dates.strftime('%Y-%m-%d')\n",
    "ax1.set_xticks(dates[::5])  # Intervalo ajustável\n",
    "ax1.set_xticklabels(formatted_labels[::5], rotation=90, fontsize=8)\n",
    "\n",
    "# Labels e títulos\n",
    "ax1.set_xlabel('Tempo')\n",
    "ax1.set_ylabel('Temperatura (°C)')\n",
    "ax2.set_ylabel('Diferença / Dias Consecutivos', color='orangered')\n",
    "ax1.set_title('Temperatura Estimada (T), Temperatura MLT (O), Diferença (t-O) e Dias Consecutivos Acima da MLT')\n",
    "\n",
    "# Grade e layout\n",
    "ax1.grid(True, linestyle='--', alpha=0.5)\n",
    "ax1.legend(loc='upper left')\n",
    "ax2.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
