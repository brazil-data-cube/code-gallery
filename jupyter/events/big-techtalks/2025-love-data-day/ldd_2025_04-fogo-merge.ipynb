{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "397e59c1-a605-463f-a0e6-3aea812866eb",
   "metadata": {},
   "source": [
    "<img src=\"https://s0.cptec.inpe.br/webcptec/sites/www/assets/img/logo_cptec.png\" align=\"right\" width=\"64\"/>\n",
    "\n",
    "# <div style=\"text-align: center;\"><span style=\"color:#336699; font-size: 1.2em;\">1º Love Data Day - BIG TechTalks:<br><span style=\"color:#336699; font-style: italic;\">      Usando Dados de Precipitação e STAC Browser para Avaliar o \"Dia do Fogo em SP\"</span></span></div>\n",
    "<hr style=\"border:2px solid #0077b9;\">\n",
    "\n",
    "<br/>\n",
    "\n",
    "<div style=\"text-align: center;font-size: 90%;\">\n",
    "    Alex de Almeida Fernandes<sup><a href=\"https://orcid.org/0000-0003-1520-5896\"><i class=\"fab fa-lg fa-orcid\" style=\"color: #a6ce39\"></i></a></sup>\n",
    "    <br/><br/>\n",
    "    Divisão de Previsão de Tempo e Clima, Instituto Nacional de Pesquisas Espaciais (INPE)\n",
    "    <br/>\n",
    "    Rodovia Presidente Dutra, km 40, Cachoeira Paulista, SP 12630-000, Brazil\n",
    "    <br/><br/>\n",
    "    Contato: <a href=\"mailto:alex.fernandes@inpe.br\">alex.fernandes@inpe.br</a>\n",
    "    <br/><br/>\n",
    "    Ultíma Atualização: 27 de Maio de 2025\n",
    "</div>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<div style=\"text-align: justify;  margin-left: 25%; margin-right: 25%;\">\n",
    "<b>Resumo.</b> Este Jupyter Notebook é parte do BIG TechTalks, edição especial <i>Love Data Days</i> - Acesso, Visualização e Processamento de dados de precipitação diária acumulada do dado MERGE produzido no INPE. O dado MERGE consiste na combinação dos dados de superfície das estações em conformidade com o padrão da Organização Meteorológica Mundial e dados de estimativas de precipitação por satélite IMERG/GPM. Esta combinação torna a estimativa de satélite mais precisa e permite o uso em locais onde não há observações de superfície nas proximidades. Este Jupyter Notebook apresenta uma visão geral de como utilizar o serviço STAC na linguagem Python para descoberta e acesso aos produtos de dados de sensoriamento remoto disponíveis no catálogo do INPE, além de demonstrar a abertura de arquivos no formato GRIB2 e como visualizar os dados de precipitação.\n",
    "<br/><br/>\n",
    "<b>Referências.</b><br> \n",
    "<a href=\"https://www.tandfonline.com/doi/full/10.1080/01431161.2020.1763504 \" target=\"_blank\">Performance of precipitation products obtained from combinations of satellite and surface observations</a>\n",
    "<a href=\"https://doi.org/10.3390/rs10060882 \" target=\"_blank\">Evaluation of TRMM/GPM Blended Daily Products over Brazil</a>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f476d888-ed82-40fb-9cae-bd64ac213041",
   "metadata": {},
   "source": [
    "# Dia do Fogo em SP - 23 de Agosto de 2024\n",
    "\n",
    "No dia 23 de agosto de 2024 um evento chamou atenção pública pela ocorrência de diversos focos de fogo iniciando em horários próximos na região norte e oeste do estado de São Paulo.\n",
    "A intenção deste notebook é demonstrar as _condições de fogo_ baseando-se na precipitação ocorrida até 3 meses antes. \n",
    "\n",
    "Os dados de precipitação utilizados será a base do MERGE/INPE, que combina dados observados em superfície com estimativas de satélite, fornecendo um dado mais preciso do que a estimativa pura.\n",
    "\n",
    "A precipitação ocorrida no perído de 2024 será comparada com a média de longo termo iniciada em 2000, dete modo, teremos uma comparação da quantidade de chuva média em 24 anos e no ano de ocorrência do evento. Será que houve menos chuva nesse período? O solo e a vegetação estavam mais secos e apresentavam condições para que o fogo fosse difícil de controlar? \n",
    "\n",
    "Vamos olhar os dados..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73163a6a-1070-43e4-bc21-cdd2338b9b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install xarray cfgrib netcdf4\n",
    "%pip install cartopy\n",
    "%pip install geopandas\n",
    "%pip install regionmask\n",
    "\n",
    "#%pip show cartopy\n",
    "#%pip show cfgrib\n",
    "\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60219ead-b4d4-4f12-b13b-6479d8299ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pystac_client\n",
    "import pystac\n",
    "import itertools\n",
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from pathlib import Path\n",
    "from dateutil.parser import parse\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "os.environ['PROJ_LIB'] = \"/opt/conda/envs/geospatial/share/proj\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8cf20a-0e0c-4cb1-8d06-7cbc1a7ec411",
   "metadata": {},
   "source": [
    "## 1. Serviço STAC e Coleções\n",
    "\n",
    "Notebook de demonstração de acesso ao catálogo e da coleção de interesse, neste caso o MERGE com acumulado diário de precipitação em formato _GRIB2_.\n",
    "\n",
    "Boa parte dos produtos de imagem disponibilizados no catálogo de imagens do INPE são disponibilizados de maneira aberta na forma de arquivos otimizados para cloud, o denominado formato Cloud Optimized GeoTIFF (COG). Este formato permite que as aplicações possam utilizar as imagens através da Web com o melhor compromisso possível, incluindo o uso de pirâmide de multi-resolução para aplicações de visualização ou até mesmo a recuperação parcial de porções de uma imagem. O COG e o serviço de análise da BIG/INPE permite várias análises e fecilidades com tal formato, que não será o caso deste notebook. \n",
    "\n",
    "Os produtos de dados podem ser consultados utilizando uma interface de programação de aplicações baseada no padrão aberto SpatioTemporal Asset Catalog (STAC). Esta especificação, criada por organizações e especialistas do setor geoespaciall.\n",
    "\n",
    "Em que:\n",
    "\n",
    "- **Catalog**: É um tipo de objeto que fornece uma estrutura para vincular vários itens ou coleções STAC juntos ou mesmo outros catálogos. Na figura acima, o catálogo é composto de três coleções: Landsat/OLI, CBERS4/WFI e Sentinel-2/MSI.\n",
    "\n",
    "- **Collection:** É uma especialização do catálogo que permite incluir informações adicionais sobre uma determinada coleção espaço-temporal. Uma coleção pode conter informações como o conjunto de bandas espectrais disponíveis das imagens, a extensão geográfica ou área de cobertura das imagens, o período de tempo que compreende a coleção, entre outras informações. Em geral, através da coleção chegamos aos itens dessa coleção.\n",
    "\n",
    "- **Item**: Corresponde à unidade atômica de metadados, fornecendo *links* para os *assets* associados. Um *Item* é descrito através da notação GeoJSON, como uma feição (*feature*) contendo atributos específicos como a coleção a que ele pertence, propriedades temporais, *links* para os *assets* e coleções ou catálogos associados. Na figura acima, um `Item` equivale a uma cena obtida por um satélite em um determinado instante de tempo.\n",
    "\n",
    "- **Asset**: Um *asset* é qualquer recurso geoespacial, como um arquivo de imagem ou arquivo vetorial, contendo informações sobre a supefície da Terra, em um determinado espaço e tempo.\n",
    "\n",
    "\n",
    "A especificação conceitual do STAC permite dois tipos de implementações:\n",
    "\n",
    "- **STAC estático:** Baseada em um conjunto de documentos JSON ligados que podem ser facilmente navegados. Ex: [CBERS na AWS](https://cbers-stac-1-0-0.s3.amazonaws.com/CBERS4/catalog.json).\n",
    "\n",
    "- **STAC dinâmico:** Baseada em uma API RESTful, de modo que a navegação é realizada através de uma API de serviço web que permite realizar consultas utilizando uma linguagem padrão para acessar subconjuntos do catálogo. Ex: [BDC-STAC](https://data.inpe.br/bdc/stac/v1).\n",
    "\n",
    "\n",
    "<br/>\n",
    "<div style=\"text-align: justify;  margin-left: 25%; margin-right: 25%;font-size: 75%; border-style: solid; border-color: #0077b9; border-width: 1px; padding: 5px;\">\n",
    "    <b>Nota:</b> Como parte do aperfeiçoamento dos produtos e serviços disponibilizados pelo INPE à sociedade, encontra-se em desenvolvimento o novo portal <a href=\"https://data.inpe.br/\">https://data.inpe.br/</a>, que faz parte da modernização da infraestrutura de serviços para acesso às imagens de satélites do acervo do instituto. Esse portal foi criado com o intuito de facilitar a pesquisa e obtenção das imagens disponibilizadas gratuitamente. Esse novo serviço tem como base as tecnologias desenvolvidas no projeto Brazil Data Cube, e está ancorado dentro do Programa Base de Informações Georreferenciadas (BIG) do INPE. Para navegar pelas coleções disponibilizadas no serviço STAC do INPE, utilize a instância do [STAC Browser](https://data.inpe.br/stac/browser/).\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cace998d-a738-428a-a1b8-0700119a7723",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PySTAC\n",
    "service = pystac_client.Client.open('https://data.inpe.br/bdc/stac/v1/')\n",
    "service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73650df-74a1-4584-8a2b-80dd548b8964",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = service.get_collection('prec_merge_daily-1')\n",
    "collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadf4251-4e55-43d4-94bf-3c2ed0db6e15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T14:06:53.221947Z",
     "iopub.status.busy": "2025-06-02T14:06:53.221144Z",
     "iopub.status.idle": "2025-06-02T14:06:53.226915Z",
     "shell.execute_reply": "2025-06-02T14:06:53.226150Z",
     "shell.execute_reply.started": "2025-06-02T14:06:53.221922Z"
    }
   },
   "source": [
    "### Função para baixar e ler uma série de dados do STAC.\n",
    "Atualmente estão sendo utilizados dados de precipitação do MERGE. Tais dados estão em formato GRIB2 e não podem ser acessados diretamente pelo XARRAY; precisam que seja feito o download e depois a leitura.\n",
    "\n",
    "Na função _Download_and_read_merge_stac_, usamos a bibliotec _requests_ para fazer o download do link HTTPS;\n",
    "depois, XARRAY abre todos os arquivos com _open_mfdataset_\n",
    "\n",
    "Para a função, deve-se passar o serviço do pystac_client que foi aberto, uma data inicial e final e o diretório onde os dados serão baixados.\n",
    "se a data inicial for igual a final, apenas um dia será baixado.\n",
    "\n",
    "    Busca, baixa e lê dados MERGE em formato GRIB2 do catálogo STAC do INPE,\n",
    "    filtrando por um período de datas. \n",
    "\n",
    "    Args:\n",
    "        stac_catalog_url (str): URL do catálogo/item STAC do INPE que contém o MERGE diário.\n",
    "        start_date (str): Data inicial (formato ISO ou legível, ex: '2024-01-01').\n",
    "        end_date (str): Data final (formato ISO ou legível, ex: '2024-01-31').\n",
    "        output_dir (str): Pasta onde salvar os arquivos baixados.\n",
    "\n",
    "    Returns:\n",
    "        ds (xarray.Dataset): Dataset final contendo os dados do merge com a dimensão tempo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07eb7a8-f370-44e0-a79e-efd80811b152",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_read_merge_stac(\n",
    "    stac_service: str,\n",
    "    start_date: str,\n",
    "    end_date: str,\n",
    "    output_dir: str = \"merge_data\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Busca, baixa e lê dados MERGE em formato GRIB2 do catálogo STAC do INPE,\n",
    "    filtrando por um período de datas. \n",
    "\n",
    "    Args:\n",
    "        stac_catalog_url (str): URL do catálogo/item STAC do INPE que contém o MERGE diário.\n",
    "        start_date (str): Data inicial (formato ISO ou legível, ex: '2024-01-01').\n",
    "        end_date (str): Data final (formato ISO ou legível, ex: '2024-01-31').\n",
    "        output_dir (str): Pasta onde salvar os arquivos baixados.\n",
    "\n",
    "    Returns:\n",
    "        ds (xarray.Dataset): Dataset final contendo os dados do merge com a dimensão tempo.\n",
    "    \"\"\"\n",
    "    # Converte datas para objetos datetime\n",
    "    start_dt = parse(start_date)\n",
    "    end_dt = parse(end_date)\n",
    "\n",
    "    # Cria diretório de saída se não existir\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(exist_ok=True)\n",
    "\n",
    "    downloaded_files = []\n",
    "\n",
    "    if isinstance(service, pystac.Catalog) and stac_service.id == 'INPE':  # acesso stac server do INPE\n",
    "        item_search = service.search(datetime=start_date+'/'+end_date,     # Pesquisa apenas as datas de interesse na coleção prec_merge_daily-1\n",
    "                             collections=['prec_merge_daily-1'])\n",
    "        for asset in item_search.items():                                  # verifica os assets dos itens encontrados anteriormente\n",
    "            if asset.assets['merge_daily'].href.endswith(\".grib2\"):        # Acessa apenas os links dos dados GRIB2, há outros como o idx e ctl.\n",
    "                file_url = asset.assets['merge_daily'].href\n",
    "                filename = Path(file_url).name\n",
    "                file_path = output_path / filename\n",
    "\n",
    "                #print(f\"Baixando: {file_url}\")\n",
    "                response = requests.get(file_url, stream=True)             # Baixa os dados \n",
    "                response.raise_for_status()\n",
    "\n",
    "                with open(file_path, \"wb\") as f:\n",
    "                    for chunk in response.iter_content(chunk_size=1024 * 1024):\n",
    "                        if chunk:\n",
    "                            f.write(chunk)\n",
    "\n",
    "                        print(f\"Arquivo salvo: {file_path}\")\n",
    "                        downloaded_files.append(file_path)                # Adiciona novo arquivo baixado na lista de arquivos para abertura com o xarray\n",
    "    else:\n",
    "        raise ValueError(\"STAC URL deve apontar para um Catálogo ou Item.\")\n",
    "\n",
    "    # Verifica se algum arquivo foi baixado\n",
    "    if not downloaded_files:\n",
    "        raise FileNotFoundError(\"Nenhum arquivo .grib2 foi encontrado no período especificado.\")\n",
    "\n",
    "    # Lê os arquivos com xarray\n",
    "    print(\"Lendo arquivos com xarray...\")\n",
    "          \n",
    "    # Lê múltiplos arquivos com open_mfdataset, aplicando a função preprocess\n",
    "    ds = xr.open_mfdataset(\n",
    "        downloaded_files,\n",
    "        engine='cfgrib',\n",
    "        combine='nested',\n",
    "        concat_dim='time',\n",
    "        decode_timedelta=False)\n",
    "\n",
    "    return ds\n",
    "\n",
    "ds = download_and_read_merge_stac(service, '2024-05-01', '2024-08-31', './data/merge')\n",
    "ds = ds.sortby('time')  # O download pode não ter ocorrido na ordem de datas, portanto ordena o dado pela dimensão _time_\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cecb55-38ae-43a8-bf60-74c07bbbee65",
   "metadata": {},
   "source": [
    "## 2. Plots!!\n",
    "\n",
    "Vamos ver as chuvas que ocorreram em um período anterior à 3 meses do evento do _Dia do Fogo em SP_.\n",
    "\n",
    "Chuvas que ocorreram próximas ao _dia do fogo_, podem indicar condições desfavoráveis; quanto mais seca vegetação e o solo, melhores são as condições.\n",
    "\n",
    "Observações importantes:\n",
    "\n",
    "- **Chuva**: Consideramos _chuva_ dados acima de 1mm.\n",
    "- **Chuva fraca**: Será considerado como chuva fraca o limiar menor ou igual à 10mm/dia.\n",
    "- **MLT**: Média de longo termo, ou a média de 24 anos de dados MERGE\n",
    "- **Classificação de chuva**: Classificação do acumulado de chuva\n",
    "\n",
    "<table border=\"1\">\n",
    "    <tr>\n",
    "        <th>Classificação</th>\n",
    "        <th>Precipitação Acumulada (mm/dia)</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Fraca</td>\n",
    "        <td>0 - 5</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Moderada</td>\n",
    "        <td>5.1 - 20</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Forte</td>\n",
    "        <td>20.1 - 50</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Muito Forte</td>\n",
    "        <td>50.1 - 100</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Extrema</td>\n",
    "        <td>100+</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "Fonte: https://www.portalmultiplix.com/noticias/cotidiano/meteorologista-do-inmet-explica-como-classificar-a-intensidade-das-chuvas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2465bdb5-00ef-4586-a91b-bf044e9f1f8e",
   "metadata": {},
   "source": [
    "### Função básica para os plots\n",
    "\n",
    "Função para plotar as imagens, podendo recortar em área, escolher variável, mapa de cores e escala de valores.\n",
    "Preparada com valores padrão para o MERGE diário, para outros dados deve-se usar os argumentos.\n",
    "\n",
    "    Usa _XARRAY DATASET_ para plotar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe2a80b-d9dc-4a61-af74-2fbed8dc9c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precipitacao_merge(\n",
    "    ds,\n",
    "    var='rdp',\n",
    "    title='Precipitação Total (MERGE)',\n",
    "    cmap='YlGnBu',\n",
    "    levels=np.linspace(0, 50, 51),\n",
    "    extent=[-85, -34, -60, 15]  # Extent da América do Sul\n",
    "):\n",
    "    \"\"\"\n",
    "    Plota a variável de precipitação do dataset MERGE para a América do Sul.\n",
    "\n",
    "    Args:\n",
    "        ds (xarray.Dataset): Dataset com os dados lidos (ex: de xr.open_dataset).\n",
    "        var (str): Nome da variável de precipitação. Padrão: 'tp' (total precipitation).\n",
    "        title (str): Título do gráfico.\n",
    "        cmap (str): Colormap usado.\n",
    "        levels (array): Níveis do contorno para o plot.\n",
    "        extent (list): [min_lon, max_lon, min_lat, max_lat] da região a ser plotada.\n",
    "    \"\"\"\n",
    "    # Definir projeção\n",
    "    proj = ccrs.PlateCarree()\n",
    "\n",
    "    # Criar figura e eixo com projeção geográfica\n",
    "    fig, ax = plt.subplots(figsize=(12, 8), subplot_kw={'projection': proj})\n",
    "\n",
    "    # Seleciona a variável e plota\n",
    "    pcm = ds[var].plot.pcolormesh(\n",
    "        ax=ax,\n",
    "        transform=proj,\n",
    "        cmap=cmap,\n",
    "        levels=levels,\n",
    "        extend='max',\n",
    "        add_colorbar=True,\n",
    "        cbar_kwargs={'shrink': 0.7, 'label': 'Precipitação (mm/h)'}\n",
    "    )\n",
    "\n",
    "    # Configurações do mapa\n",
    "    ax.set_title(title, fontsize=14)\n",
    "    ax.set_extent(extent, crs=proj)\n",
    "\n",
    "    # Adicionar limites continentais e países\n",
    "    ax.add_feature(cfeature.LAND, facecolor='lightgray')\n",
    "    ax.add_feature(cfeature.OCEAN, facecolor='white')\n",
    "    ax.add_feature(cfeature.COASTLINE, linewidth=0.8)\n",
    "    ax.add_feature(cfeature.BORDERS, linewidth=0.5, linestyle=':')\n",
    "    ax.add_feature(cfeature.STATES, linewidth=0.3, alpha=0.5)\n",
    "\n",
    "    # Grid e rótulos\n",
    "    gl = ax.gridlines(draw_labels=True, linewidth=0.5, color='gray', alpha=0.7, linestyle='--')\n",
    "    gl.top_labels = False\n",
    "    gl.right_labels = False\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa15225-3669-4067-92ac-1ea9a1e2d6a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T14:59:55.927742Z",
     "iopub.status.busy": "2025-06-02T14:59:55.926888Z",
     "iopub.status.idle": "2025-06-02T14:59:55.935791Z",
     "shell.execute_reply": "2025-06-02T14:59:55.934577Z",
     "shell.execute_reply.started": "2025-06-02T14:59:55.927710Z"
    }
   },
   "source": [
    "### Exemplo de uso da função para plotar dados.\n",
    "\n",
    "Primeiro uma imagem da América do Sul e depois repassando apenas o intervalo de interesse, Estado de São Paulo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5852b6f4-1ad4-45dc-b4aa-15665c21af37",
   "metadata": {},
   "outputs": [],
   "source": [
    "dy = ds.mean(dim='time')\n",
    "print(dy)\n",
    "\n",
    "plot_precipitacao_merge(dy, levels=np.linspace(0, 10, 11))\n",
    "plot_precipitacao_merge(ds.mean(dim='time'), \n",
    "                        extent=[-52.9518,-44.1291,-25.7323,-19.2479], \n",
    "                        levels=np.linspace(0, 5, 6),\n",
    "                        title='Precipitação MERGE média diária '+str(ds.time.min().values)[0:13]+'/'+str(ds.time.max().values)[0:13]\n",
    "                       )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f1fbd2-46c6-4b9c-a59b-c33be5b4d432",
   "metadata": {},
   "source": [
    "### Função para recortar o Datase \n",
    "\n",
    "Recorta os dados apenas na região de interesse visando um local onde houveram mais focos.\n",
    "Utilizada _sel_ do XARRAY para realizar os recortes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbe19c4-fcdf-4648-b2b0-817d85316911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recortar_dataset_por_regiao(ds, lon_min, lon_max, lat_min, lat_max):\n",
    "    \"\"\"\n",
    "    Recorta o dataset ou dataArray para uma região retangular definida por lat/lon.\n",
    "\n",
    "    Args:\n",
    "        ds (xarray.Dataset or xarray.DataArray): O dataset ou array a ser recortado.\n",
    "        lon_min (float): Longitude mínima da região.\n",
    "        lon_max (float): Longitude máxima da região.\n",
    "        lat_min (float): Latitude mínima da região.\n",
    "        lat_max (float): Latitude máxima da região.\n",
    "\n",
    "    Returns:\n",
    "        xarray.Dataset or xarray.DataArray: Dataset/DataArray recortado para a região especificada.\n",
    "    \"\"\"\n",
    "    # Verifica se as dimensões estão corretas\n",
    "    if 'latitude' in ds.dims and 'longitude' in ds.dims:\n",
    "        # Aplica o recorte\n",
    "        recortado = ds.sel(\n",
    "            longitude=slice(360+lon_min, 360+lon_max),\n",
    "            latitude=slice(lat_min,lat_max)  # Ordem decrescente em latitude é comum em datasets\n",
    "        )\n",
    "    elif 'lat' in ds.dims and 'lon' in ds.dims:\n",
    "        # Aplica o recorte\n",
    "        recortado = ds.sel(\n",
    "            lon=slice(lon_min, lon_max),\n",
    "            lat=slice(lat_min,lat_max)  # Ordem decrescente em latitude é comum em datasets\n",
    "    )\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"O dataset deve conter as dimensões 'latitude' e 'longitude'.\")\n",
    "\n",
    "\n",
    "    return recortado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb64743-45a5-446c-b26c-ea2a16b6d02a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T17:05:05.432097Z",
     "iopub.status.busy": "2025-06-02T17:05:05.431107Z",
     "iopub.status.idle": "2025-06-02T17:05:05.435122Z",
     "shell.execute_reply": "2025-06-02T17:05:05.434481Z",
     "shell.execute_reply.started": "2025-06-02T17:05:05.432069Z"
    }
   },
   "source": [
    "### Dados recortados ds_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f19a26-96a7-4132-8af7-6026f1562f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar máscara\n",
    "#ds_sp = mask_sp_dataset_ibge_2024(ds)\n",
    "ds_sp = recortar_dataset_por_regiao(ds, -52.9518,-45.2291,-22,-19.2479)\n",
    "ds_sp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f1e1ae-3b2b-4332-b8ca-2c03517c98bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_precipitacao_merge(ds_sp.mean(dim='time'), \n",
    "#                        extent=[-53.9518,-44.1291,-23.7323,-18.2479], \n",
    "#                        levels=np.linspace(0, 2, 21),\n",
    "#                        cmap = 'RdBu')\n",
    "#\n",
    "#ds_sp['rdp'].max(axis=[1,2]).plot(figsize=(12, 5))\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec74cf1f-2b2a-4e9e-9f12-d993842b210f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T17:05:43.602424Z",
     "iopub.status.busy": "2025-06-02T17:05:43.601469Z",
     "iopub.status.idle": "2025-06-02T17:05:43.605355Z",
     "shell.execute_reply": "2025-06-02T17:05:43.604664Z",
     "shell.execute_reply.started": "2025-06-02T17:05:43.602397Z"
    }
   },
   "source": [
    "### Verificação da precipitação no estado de São Paulo\n",
    "\n",
    "A linha vermelha indica os valores máximos de precipitação que ocorreram na região de interesse.\n",
    "As colunas azuis indicam a precipitação máxima quando a média na região do recorte foi maior que 1mm.\n",
    "\n",
    "Esse filtro na precipitação foi colocado com limiar de 1mm por considerarmos chuva abaixo de 1mm como _não chuva_ em comparações numéricas com dados de estimativas de satélite.\n",
    "\n",
    "**Identificamos chuva no dia 10/08 e dia 25-26/08**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2261e9b-ca81-4c18-8d30-e45d43a064d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = ds_sp['time'][ds_sp['rdp'].mean(axis=[1,2]).values > 1]\n",
    "tp = ds_sp['rdp'][ds_sp['rdp'].mean(axis=[1,2]).values > 1].max(axis=[1,2])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.bar(dt, tp, width=0.9, color='skyblue', edgecolor='black')   #\n",
    "ax.plot(ds_sp['time'],ds_sp['rdp'].max(axis=[1,2]), color='red')\n",
    "# Mostrar todas as datas\n",
    "dates = pd.to_datetime(dt.values)\n",
    "formatted_labels = dates.strftime('%Y-%m-%d')\n",
    "ax.set_xticks(dt)  # Força todos os ticks\n",
    "ax.set_xticklabels(formatted_labels, rotation=90)\n",
    "\n",
    "ax.set_xlabel('Tempo')\n",
    "ax.set_ylabel('Precipitação Média (mm/h)')\n",
    "ax.set_title('Precipitação Média Diária no Estado de São Paulo')\n",
    "plt.tight_layout()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09327bf8-a1ab-4d11-a2d0-866f68835337",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T17:10:00.787347Z",
     "iopub.status.busy": "2025-06-02T17:10:00.786353Z",
     "iopub.status.idle": "2025-06-02T17:10:00.792230Z",
     "shell.execute_reply": "2025-06-02T17:10:00.791271Z",
     "shell.execute_reply.started": "2025-06-02T17:10:00.787312Z"
    }
   },
   "source": [
    "---\n",
    "Dia 10/08 é relativamente próximo temporalmente do evento do dia do fogo em SP.\n",
    "Deste modo, resolvemos plotar o dia 10/08 para ver como foi a distribuição da chuva no retângulo de interesse.\n",
    "\n",
    "Neste caso, o acumulado de chuva que não foi tão expressivo, foi localizado principalmente ao sul de nossa região."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4728fe7-8cd9-4979-a422-03b3eb020cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precipitacao_merge(ds_sp.sel(time='2024-08-10').mean(dim='time'), \n",
    "                        extent=[-53.9518,-44.1291,-23.7323,-18.2479], \n",
    "                        levels=np.linspace(0, 20, 41),\n",
    "                        cmap = 'RdBu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbc7581-2305-4ace-9c88-ff3baf1bbb4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T17:12:59.221893Z",
     "iopub.status.busy": "2025-06-02T17:12:59.221195Z",
     "iopub.status.idle": "2025-06-02T17:12:59.227639Z",
     "shell.execute_reply": "2025-06-02T17:12:59.226784Z",
     "shell.execute_reply.started": "2025-06-02T17:12:59.221862Z"
    }
   },
   "source": [
    "### Climatologia\n",
    "\n",
    "Não sabemos se esta quantidade de chuva é normal para o período e região, deste modo, devemos plotar a média de longo termo dos dados.\n",
    "Para isso, usaremos a média de 24 anos do MERGE diário; este dado já está calculado e em um diretório HTTPS ainda não cadastrado no STAC:\n",
    "\n",
    "https://ftp.cptec.inpe.br/modelos/tempo/MERGE/GPM/CLIMATOLOGY/DAILY_AVERAGE\n",
    "\n",
    "Novamente, vamos usar nossa função para download e leitura dos dados. Agora em NetCDF.\n",
    "A função foi levemente modificada para ler NetCDF e o diretório dos dados sem utilizar o STAC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2529a54c-1d3a-417d-8f5d-a53f123f501e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_mlt_precipitation_data(\n",
    "    start_date='2024-05-01',\n",
    "    end_date='2024-08-31',\n",
    "    output_dir='mlt_data'\n",
    "):\n",
    "    \"\"\"\n",
    "    Baixa e carrega dados MERGE-LT de precipitação entre duas datas, usando o formato %d%b no nome do arquivo.\n",
    "\n",
    "    Args:\n",
    "        start_date (str): Data inicial (formato 'YYYY-MM-DD').\n",
    "        end_date (str): Data final (formato 'YYYY-MM-DD').\n",
    "        output_dir (str): Pasta local para salvar os arquivos baixados.\n",
    "\n",
    "    Returns:\n",
    "        ds (xarray.Dataset): Dataset com todos os dados concatenados.\n",
    "    \"\"\"\n",
    "    # Criar pasta de saída se não existir\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(exist_ok=True)\n",
    "\n",
    "    # Gerar lista de datas\n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "\n",
    "    downloaded_files = []\n",
    "\n",
    "    for dt in date_range:\n",
    "        # Formato dia + mês abreviado em minúsculo (ex: '01jun', '31ago')\n",
    "        day_month = dt.strftime('%d%b').lower()  # '29Mar' -> '29mar'\n",
    "\n",
    "        filename = f\"MERGE_CPTEC_12Z{day_month}.nc\"\n",
    "        file_url = f\"https://ftp.cptec.inpe.br/modelos/tempo/MERGE/GPM/CLIMATOLOGY/DAILY_AVERAGE/{filename}\"\n",
    "\n",
    "        file_path = output_path / filename\n",
    "\n",
    "        print(f\"Baixando: {file_url}\")\n",
    "\n",
    "        response = requests.get(file_url, stream=True)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            with open(file_path, 'wb') as f:\n",
    "                for chunk in response.iter_content(chunk_size=1024 * 1024):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "            downloaded_files.append(file_path)\n",
    "        else:\n",
    "            print(f\"Arquivo não encontrado: {file_url}\")\n",
    "\n",
    "    if not downloaded_files:\n",
    "        raise FileNotFoundError(\"Nenhum arquivo foi baixado.\")\n",
    "\n",
    "    print(f\"{len(downloaded_files)} arquivos baixados. Carregando com xarray...\")\n",
    "\n",
    "    # Abrir múltiplos arquivos com xarray\n",
    "    ds = xr.open_mfdataset(\n",
    "        downloaded_files,\n",
    "        combine='by_coords'\n",
    "    )\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbafdaa-8e0f-4364-b071-b76f518bda41",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_mlt = download_mlt_precipitation_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c5cca9-a25e-4fd6-9e0e-bdb44321d25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_mlt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be273f6-8049-464f-8ea5-47729fa798fe",
   "metadata": {},
   "source": [
    "## 3. Comparação Perído e MLT\n",
    "\n",
    "### Comparação visual\n",
    "\n",
    "Primeiro vamos comparar a média espacial da MLT e do período. Qual será o mais seco?\n",
    "Depois o dia 10/08 na MLT.\n",
    "\n",
    "Essa comparação visual permite vermos que o período em questão foi mais seco que o normal. E em relação ao dia 10, como será a distribuição dessa chuva temporalmente?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b046fb-4a4f-4c46-a3a6-f23ad6e88d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sp_mlt = recortar_dataset_por_regiao(ds_mlt, -52.9518,-45.2291,-22,-19.2479)\n",
    "\n",
    "plot_precipitacao_merge(ds_sp.mean(dim=['time']), \n",
    "                        extent=[-53.9518,-44.1291,-23.7323,-18.2479], \n",
    "                        levels=np.linspace(0, 2, 21),\n",
    "                        cmap = 'RdBu')\n",
    "\n",
    "plot_precipitacao_merge(ds_sp_mlt.mean(dim=['time']), \n",
    "                        extent=[-53.9518,-44.1291,-23.7323,-18.2479], \n",
    "                        levels=np.linspace(0, 2, 21),\n",
    "                        var='pmed',\n",
    "                        cmap = 'RdBu',\n",
    "                        title='Média de Longo Termo')\n",
    "\n",
    "plot_precipitacao_merge(ds_sp_mlt.sel(time='2020-08-10').mean(dim='time'), \n",
    "                        extent=[-53.9518,-44.1291,-23.7323,-18.2479], \n",
    "                        levels=np.linspace(0, 20, 21),\n",
    "                        var='pmed',\n",
    "                        cmap = 'RdBu',\n",
    "                        title='Média no dia 10/08 MLT')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8881eba1-3eac-45b7-969c-c38ab63badb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T17:18:16.663339Z",
     "iopub.status.busy": "2025-06-02T17:18:16.662508Z",
     "iopub.status.idle": "2025-06-02T17:18:16.666380Z",
     "shell.execute_reply": "2025-06-02T17:18:16.665762Z",
     "shell.execute_reply.started": "2025-06-02T17:18:16.663308Z"
    }
   },
   "source": [
    "### Comparação média diária MLT e o _Dia do Fogo_\n",
    "\n",
    "No gráfico abaixo, colunas vermelhas são a climatologia, a média de 24 anos do MERGE.\n",
    "As colunas azuis são as precipitações observadas para a média do retângulo no intervalo temporal de interesse.\n",
    "\n",
    "Vemos que o mês de maio foi um mês completamente diferente da média, sendo muito mais seco que o normal.\n",
    "\n",
    "Talvez estas sejam condições (parciais) para o fogo..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018d0656-4894-4eb6-956b-0262bc5ac8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = ds_sp['time'][ds_sp['rdp'].mean(axis=[1,2]).values > 1]\n",
    "tp = ds_sp['rdp'][ds_sp['rdp'].mean(axis=[1,2]).values > 1].mean(axis=[1,2])\n",
    "\n",
    "dt2 = ds_sp['time'][:123][ds_sp_mlt['pmed'].mean(axis=[1,2]).values > 1]\n",
    "tp2 = ds_sp_mlt['pmed'][ds_sp_mlt['pmed'].mean(axis=[1,2]).values > 1].max(axis=[1,2])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.bar(dt2, tp2, width=0.8, color='red', edgecolor='red', alpha=0.5)\n",
    "ax.bar(dt, tp, width=0.8, color='skyblue', edgecolor='blue', alpha=0.5)\n",
    "\n",
    "# Mostrar todas as datas\n",
    "dates = pd.to_datetime(dt.values)\n",
    "formatted_labels = dates.strftime('%Y-%m-%d')\n",
    "ax.set_xticks(dt)  # Força todos os ticks\n",
    "ax.set_xticklabels(formatted_labels, rotation=90)\n",
    "\n",
    "ax.set_xlabel('Tempo')\n",
    "ax.set_ylabel('Precipitação Média (mm/h)')\n",
    "ax.set_title('Precipitação Média Diária no Estado de São Paulo')\n",
    "plt.tight_layout()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
