{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e301eadd-fe20-47fc-a2b7-2d9a864c4a98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T16:44:44.459270Z",
     "iopub.status.busy": "2025-05-21T16:44:44.414702Z",
     "iopub.status.idle": "2025-05-21T16:44:44.481617Z",
     "shell.execute_reply": "2025-05-21T16:44:44.480169Z"
    }
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/brazil-data-cube/code-gallery/master/img/logo-bdc.png\" align=\"right\" width=\"64\"/>\n",
    "\n",
    "# <span style=\"color:#336699\">BIG Love Data Day - Sensoriamento Remoto aplicado ao estudo de ecossistemas de água doce</span>\n",
    "<hr style=\"border:2px solid #0077b9;\">\n",
    "\n",
    "<div style=\"text-align: left;\">\n",
    "    <a href=\"https://nbviewer.jupyter.org/github/brazil-data-cube/code-gallery/blob/master/jupyter/Python/stac/stac-introduction.ipynb\"><img src=\"https://raw.githubusercontent.com/jupyter/design/master/logos/Badges/nbviewer_badge.svg\" align=\"center\"/></a>\n",
    "</div>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<div style=\"text-align: justify;  margin-left: 25%; margin-right: 25%;\">\n",
    "<b>Resumo.</b> Este Jupyter Notebook é parte do material do Love Data Day organizado pela <em>Base de Informações Georeferenciadas</em> (BIG) do <em>Instituto Nacional de Pesquisas Espaciais</em> (INPE). Nele é feita uma demonstração de modelagem de ecossistemas de água doce, utilizando o serviço SpatioTemporal Asset Catalog (STAC) do INPE.\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align: center;font-size: 90%;\">\n",
    "    Rogerio Flores Júnior<sup><a href=\"https://orcid.org/0000-0001-6181-2158\"><i class=\"fab fa-lg fa-orcid\" style=\"color: #a6ce39\"></i></a></sup>, Gilberto R. Queiroz<sup><a href=\"https://orcid.org/0000-0001-7534-0219\"><i class=\"fab fa-lg fa-orcid\" style=\"color: #a6ce39\"></i></a></sup>\n",
    "    <br/><br/>\n",
    "    Divisão de Observação da Terra e Geoinformática, Instituto Nacional de Pesquisas Espaciais (INPE)\n",
    "    <br/>\n",
    "    Avenida dos Astronautas, 1758, Jardim da Granja, São José dos Campos, SP 12227-010, Brazil\n",
    "    <br/><br/>\n",
    "    Contact: <a href=\"mailto:brazildatacube@inpe.br\">brazildatacube@inpe.br</a>\n",
    "    <br/><br/>\n",
    "    Data do Minicurso: 03 de junho de 2025\n",
    "</div>\n",
    "\n",
    "<br/>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1395de-c3d2-45b0-83c9-cd26db7835e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T16:54:06.168693Z",
     "iopub.status.busy": "2025-05-21T16:54:06.168114Z",
     "iopub.status.idle": "2025-05-21T16:54:06.177741Z",
     "shell.execute_reply": "2025-05-21T16:54:06.177047Z",
     "shell.execute_reply.started": "2025-05-21T16:54:06.168671Z"
    }
   },
   "source": [
    "# Contexto\n",
    "---\n",
    "\n",
    "O uso de dados de Sensoriamento Remoto para prever parâmetros de qualidade da água (QA) que são opticamente ativos (ou seja, que interagem com a luz) tem sido aplicado a águas oceânicas e costeiras há cerca de 50 anos. Graças à nova geração de sensores com resolução espectral, radiométrica e espacial adequadas (como Landsat, Sentinel-2, etc.), nos últimos 15 anos a comunidade científica começou a aplicar o sensoriamento remoto (SR) em estudos de águas interiores.\n",
    "\n",
    "O sensoriamento remoto permite prever alguns parâmetros de qualidade da água: sedimentos em suspensão, clorofila-a, ficocianina, matéria orgânica dissolvida, carbono, profundidade do disco de Secchi, turbidez... É uma fonte importante de dados que pode auxiliar biólogos, limnólogos e toda a comunidade de ciências aquáticas na compreensão dos padrões da água.\n",
    "\n",
    "Neste workshop, vamos aprender como usar dados de Sensoriamento Remoto aplicados às ciências aquáticas. Utilizaremos dados in situ disponíveis no conjunto de dados GLORIA (Lehmann et al. 2023) para gerar um modelo de aprendizado de máquina por arvores de decisão para a determinação da concentração de sólidos totais em Suspensão (TSS).\n",
    "\n",
    "Assim, com um algoritmo calibrado, aplicaremos o modelo desenvolvido aos dados de Reflectância de Superfície do Sentinel-2/MSI, corrigidos atmosfericamente usando o ACOLITE. Por via de compraração, faremos aplicação em duas data, Antes e após as enchentes no estado do Rio Grande do Sul.\n",
    "\n",
    "O fluxo de processamento está dividido em três tópicos:\n",
    "\n",
    "1) Instalação dos pacotes, download dos dados, simulação das bandas e remoção de outliers (etapa de pré-processamento);\n",
    "\n",
    "2) Desenvolvimento do modelo (treinamento, validação);\n",
    "\n",
    "3) Aplicação do modelo: aplicação dos algoritmos aos dados de satélite usando o `STAC`\n",
    "\n",
    "### O que esperamos obter como resultado?\n",
    "\n",
    "1) Um algoritmo de sólidos totais em Suspensão utilizando um modelo de aprendizado de máquina;\n",
    "\n",
    "2) Introdução a correção atmosférica de imagens para ambientes aquáticos com o ACOLITE (Vanhellemont and Ruddick, 2018) (https://www.sciencedirect.com/science/article/pii/S0034425718303481);\n",
    "\n",
    "3) Download e aplicação da correção atmosférica ACOLITE em dados Sentinel-2 L1C obtidos através do STAC do BDC;\n",
    "\n",
    "4) Comparação dos resultados entre as duas datas de análise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fee7fb8-b81c-42d1-bb32-fe5138c5f639",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T21:20:12.321415Z",
     "iopub.status.busy": "2025-05-27T21:20:12.320678Z",
     "iopub.status.idle": "2025-05-27T21:20:12.614439Z",
     "shell.execute_reply": "2025-05-27T21:20:12.613711Z",
     "shell.execute_reply.started": "2025-05-27T21:20:12.321392Z"
    }
   },
   "source": [
    "# Área de Estudo\n",
    "---\n",
    "A Bacia Hidrográfica do Lago Guaíba, localizada na Região Hidrográfica da Bacia do Guaíba, possui área de 2.919 km² e população estimada de 1.344.982 habitantes (2020), sendo 1.324.782 habitantes em áreas urbanas e 20.199 habitantes em áreas rurais.\n",
    "\n",
    "![Figure 01](https://sema.rs.gov.br/upload/recortes/202104/29082641_74342_GDO.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718a21a9-337e-43c8-b6b8-69e879498179",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T17:01:06.502091Z",
     "iopub.status.busy": "2025-05-21T17:01:06.501325Z",
     "iopub.status.idle": "2025-05-21T17:01:06.506271Z",
     "shell.execute_reply": "2025-05-21T17:01:06.505566Z",
     "shell.execute_reply.started": "2025-05-21T17:01:06.502068Z"
    }
   },
   "source": [
    "# Instalações e configurações\n",
    "---\n",
    "\n",
    "Pacotes necessários:\n",
    "\n",
    "`rasterio`\n",
    "`pandas`\n",
    "`geopandas`\n",
    "`tqdm`\n",
    "`sklearn`\n",
    "`scipy`\n",
    "`pystac`\n",
    "\n",
    "Para este minicurso vamos utilizar o ambiente python `Geospatial` do BDC que conta estas bibliotecas por padrão.\n",
    "\n",
    "mas \n",
    "\n",
    "Caso deseje efetuar a instalação usando --PyPI-- com `pip`, use os seguintes comandos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c7f21f-50bf-40fd-b60f-7ab4c56e650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install rasterio pandas geopandas tqdm pystac-client sklearn scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532e967b-4b42-4729-9c86-539e060c2029",
   "metadata": {},
   "source": [
    "Caso não tenha o pacote de simulação de bandas, descomentar e executar a célula abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afaf812-439c-48e2-938b-8b1e8a397c19",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-27T20:28:42.960227Z",
     "iopub.status.busy": "2025-05-27T20:28:42.959195Z",
     "iopub.status.idle": "2025-05-27T20:28:53.091947Z",
     "shell.execute_reply": "2025-05-27T20:28:53.091178Z",
     "shell.execute_reply.started": "2025-05-27T20:28:42.960176Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install git+https://github.com/LabISA-INPE/rotina-simulacaobandas-python.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93119b55-7d53-493a-852e-7c6cc2f734f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T13:17:03.182368Z",
     "iopub.status.busy": "2025-05-31T13:17:03.182052Z",
     "iopub.status.idle": "2025-05-31T13:17:03.186798Z",
     "shell.execute_reply": "2025-05-31T13:17:03.186299Z",
     "shell.execute_reply.started": "2025-05-31T13:17:03.182345Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importando os módulos necessários\n",
    "import os\n",
    "# Criando os diretórios\n",
    "os.makedirs(\"Data\", exist_ok=True)\n",
    "os.makedirs(\"Outputs\", exist_ok=True)\n",
    "os.makedirs(\"Scripts\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3cbb03-31a7-4578-98cf-741f9c175da5",
   "metadata": {},
   "source": [
    "# Dados\n",
    "---\n",
    "\n",
    "\n",
    "## GLORIA Dataset\n",
    "\n",
    "O conjunto de dados GLORIA é uma compilação de dados de reflectância de sensoriamento remoto (Rrs) e qualidade da água para corpos d’água em escala global, com dados dedicados a ecossistemas de água doce. É gratuito, acessível a todos e cobre grande parte do planeta, com mais de 7.000 amostras (Figura 01).\n",
    "\n",
    "Vale lembrar que a Reflectância de Sensoriamento Remoto (Rrs) é a razão entre a radiância emergente da água e a irradiância descendente, compensada pela radiância do céu e corrigida pelos efeitos de brilho especular (glint) (Equação 01).\n",
    "\n",
    "Para mais informações, consulte a publicação [(Lehmann et al. 2023)](https://www.nature.com/articles/s41597-023-01973-y) e o dataset disponível no [PANGAEA](http://https://doi.pangaea.de/10.1594/PANGAEA.948492) e [Nature Earth and Environmment blog post](https://communities.springernature.com/posts/gloria-challenges-in-developing-a-globally-representative-hyperspectral-in-situ-dataset-for-the-remote-sensing-of-water-resources)\n",
    "\n",
    "\n",
    "\n",
    "![Figure 01](https://earthenvironmentcommunity.nature.com/cdn-cgi/image/metadata=copyright,fit=scale-down,format=auto,sharpen=1,quality=95/https://images.zapnito.com/uploads/hiCMOprnTtSCTJNv78gu_locations.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9766a38-57fe-45ff-ba43-9dbc10575aa8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T16:00:05.933960Z",
     "iopub.status.busy": "2025-05-31T16:00:05.933018Z",
     "iopub.status.idle": "2025-05-31T16:00:06.400418Z",
     "shell.execute_reply": "2025-05-31T16:00:06.399730Z",
     "shell.execute_reply.started": "2025-05-31T16:00:05.933934Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "###### Baixar os dados GLORIA ##########\n",
    "URL = 'https://download.pangaea.de/dataset/948492/files/GLORIA-2022.zip'\n",
    "\n",
    "# Espera de 300s\n",
    "TIMEOUT = 300\n",
    "\n",
    "# Criando o diretório para os dados\n",
    "if not os.path.exists('Data/GLORIA_2022/'):\n",
    "    \n",
    "    # Download\n",
    "    print(\"Baixando o GLORIA...\")\n",
    "    response = requests.get(URL, timeout=TIMEOUT)\n",
    "    response.raise_for_status()  # Raises an HTTPError for bad responses\n",
    "    \n",
    "    with open('Data/GLORIA.zip', 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    \n",
    "    # Extraindo os dados\n",
    "    print(\"Extraindo o zip file...\")\n",
    "    with zipfile.ZipFile('Data/GLORIA.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('Data')\n",
    "    \n",
    "    print(\"Download e extração completas!\")\n",
    "else:\n",
    "    print(\"O diretório de dados do GLORIA já existe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58972b60-aa17-46f0-85bd-083484a3edda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T13:17:29.992608Z",
     "iopub.status.busy": "2025-05-31T13:17:29.991544Z",
     "iopub.status.idle": "2025-05-31T13:17:39.016890Z",
     "shell.execute_reply": "2025-05-31T13:17:39.016147Z",
     "shell.execute_reply.started": "2025-05-31T13:17:29.992582Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#[CODE - PLOT Gloria]\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Alternative version with even better styling\n",
    "def plot_gloria_concentrations(rrs_data, \n",
    "                                       gloria_ids=['GID_7403', 'GID_1805', 'GID_2468'],\n",
    "                                       titles=['Alta Clorofila', 'Alto Sedimento', 'Alto aCDOM'],\n",
    "                                       colors=['#228B22', '#8B4513', '#B8860B'],  # Forest Green, Saddle Brown, Dark Goldenrod\n",
    "                                       ylims=[(0, 0.06), (0, 0.06), (0, 0.0005)],\n",
    "                                       wavelength_range=(400, 900),\n",
    "                                       figsize=(16, 5.5),\n",
    "                                       title_fontsize=15):\n",
    "    \"\"\"\n",
    "    Enhanced version with better colors and styling.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set style\n",
    "    plt.style.use('default')\n",
    "    \n",
    "    # Create wavelength range and column names\n",
    "    wavelengths = list(range(wavelength_range[0], wavelength_range[1] + 1))\n",
    "    rrs_cols = [f\"Rrs_{wl}\" for wl in wavelengths]\n",
    "    \n",
    "    # Create 1x3 horizontal subplot grid with more space\n",
    "    fig, axes = plt.subplots(1, 3, figsize=figsize)\n",
    "    \n",
    "    # Plot each condition\n",
    "    for i, (gid, title, color, ylim) in enumerate(zip(gloria_ids, titles, colors, ylims)):\n",
    "        # Filter data for current GLORIA_ID\n",
    "        data = rrs_data[rrs_data['GLORIA_ID'] == gid][rrs_cols]\n",
    "        \n",
    "        if not data.empty:\n",
    "            # Plot all spectra for this condition\n",
    "            axes[i].plot(wavelengths, data.T, color=color, linewidth=2, alpha=0.9)\n",
    "            axes[i].set_ylim(ylim)\n",
    "            axes[i].set_xlim(wavelength_range)\n",
    "            axes[i].set_title(title, fontsize=title_fontsize, pad=20, fontweight='bold')\n",
    "            \n",
    "            # Enhanced grid\n",
    "            axes[i].grid(True, alpha=0.4, linestyle='-', linewidth=0.5, color='gray')\n",
    "            \n",
    "            # Clean styling\n",
    "            axes[i].spines['top'].set_visible(False)\n",
    "            axes[i].spines['right'].set_visible(False)\n",
    "            axes[i].spines['left'].set_linewidth(1.2)\n",
    "            axes[i].spines['bottom'].set_linewidth(1.2)\n",
    "            axes[i].spines['left'].set_color('#333333')\n",
    "            axes[i].spines['bottom'].set_color('#333333')\n",
    "            \n",
    "            # Tick styling\n",
    "            axes[i].tick_params(axis='both', which='major', labelsize=10, \n",
    "                              colors='#333333', width=1.2)\n",
    "            \n",
    "            # Labels\n",
    "            axes[i].set_xlabel('Wavelength (nm)', fontsize=12, fontweight='bold', \n",
    "                             color='#333333', labelpad=10)\n",
    "            \n",
    "            # Only set y-axis label for the leftmost plot\n",
    "            if i == 0:\n",
    "                axes[i].set_ylabel('Remote Sensing Reflectance', fontsize=12, \n",
    "                                 fontweight='bold', color='#333333', labelpad=10)\n",
    "        else:\n",
    "            axes[i].text(0.5, 0.5, f'No data for {gid}', \n",
    "                       transform=axes[i].transAxes, ha='center', va='center',\n",
    "                       fontsize=12, bbox=dict(boxstyle=\"round,pad=0.5\", \n",
    "                                            facecolor=\"lightcoral\", alpha=0.7))\n",
    "            axes[i].set_title(title, fontsize=title_fontsize, pad=20, fontweight='bold')\n",
    "    \n",
    "    # Adjust layout with more padding\n",
    "    plt.tight_layout(pad=3.0)\n",
    "    \n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8bb46f-6131-42ff-b6f4-fb0f7357afac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T13:17:39.018223Z",
     "iopub.status.busy": "2025-05-31T13:17:39.017897Z",
     "iopub.status.idle": "2025-05-31T13:17:43.298741Z",
     "shell.execute_reply": "2025-05-31T13:17:43.298202Z",
     "shell.execute_reply.started": "2025-05-31T13:17:39.018203Z"
    }
   },
   "outputs": [],
   "source": [
    "##### Avaliando os dados GLORIA  #######\n",
    "meta_and_lab = pd.read_csv(\"Data/GLORIA_2022/GLORIA_meta_and_lab.csv\")\n",
    "rrs = pd.read_csv(\"Data/GLORIA_2022/GLORIA_Rrs.csv\")\n",
    "\n",
    "##### Plotando os dados GLORIA #######\n",
    "fig, axes = plot_gloria_concentrations(rrs)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfdbf63-ee13-4c06-88e1-688414608dea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T13:17:48.039622Z",
     "iopub.status.busy": "2025-05-31T13:17:48.038864Z",
     "iopub.status.idle": "2025-05-31T13:17:48.060755Z",
     "shell.execute_reply": "2025-05-31T13:17:48.060269Z",
     "shell.execute_reply.started": "2025-05-31T13:17:48.039598Z"
    }
   },
   "outputs": [],
   "source": [
    "rrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82e6516-bb74-42c2-bea4-ede21c2db5d6",
   "metadata": {},
   "source": [
    "# Simulação de Bandas\n",
    "---\n",
    "\n",
    "Quando simulamos uma banda de satélite, estamos compensando as diferenças na sensibilidade dos detectores a cada comprimento de onda. A figura abaixo mostra as diferenças na função de resposta espectral para os sensores Sentinel-2A/MSI, Landsat-8/OLI e Landsat-7/ETM+. É possível notar que valores de resposta espectral relativa próximos de \"1\" indicam que o detector consegue medir (ou detectar) toda a radiância naquele comprimento de onda.\n",
    "\n",
    "Uma banda de um sensor é composta por um intervalo desses comprimentos de onda e, portanto, a banda simulada é a integração da R[rs] considerando a curva de Resposta Espectral Relativa.\n",
    "\n",
    "\n",
    "![Figure 02](https://upload.wikimedia.org/wikipedia/commons/7/7d/Spectral_responses_of_Landsat_7_ETM%2B%2C_Landsat_8_OLI_and_Sentinel_2_MSI_in_the_visible_and_near_infrared.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3e7150-acd2-4abe-9de7-2c4a65fa7723",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T17:27:06.743386Z",
     "iopub.status.busy": "2025-05-30T17:27:06.742581Z",
     "iopub.status.idle": "2025-05-30T17:56:12.417031Z",
     "shell.execute_reply": "2025-05-30T17:56:12.415345Z",
     "shell.execute_reply.started": "2025-05-30T17:27:06.743362Z"
    }
   },
   "outputs": [],
   "source": [
    "#https://github.com/LabISA-INPE/rotina-simulacaobandas-python\n",
    "\n",
    "# from Scripts.simulacaoBandas import SateliteBandSimulator\n",
    "\n",
    "# SBS = SateliteBandSimulator()\n",
    "\n",
    "# # Select bands between 400 and 900 nm and transpose\n",
    "# band_columns = [f\"Rrs_{wl}\" for wl in range(400, 901)]\n",
    "# spectra_formated = rrs[band_columns].T\n",
    "\n",
    "# # MSI Simulation\n",
    "# MSI_sim = SBS.msi(spectra=spectra_formated, point_names=rrs['GLORIA_ID'])\n",
    "#MSI_sim['s2a'].to_csv('Outputs/S2a_gloria_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914561ae-33b3-41c1-8abb-ae8d403819d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T16:00:31.419413Z",
     "iopub.status.busy": "2025-05-31T16:00:31.418820Z",
     "iopub.status.idle": "2025-05-31T16:00:31.650422Z",
     "shell.execute_reply": "2025-05-31T16:00:31.649886Z",
     "shell.execute_reply.started": "2025-05-31T16:00:31.419389Z"
    }
   },
   "outputs": [],
   "source": [
    "# lendo os dados csv\n",
    "MSI_load = pd.read_csv('Outputs/S2a_gloria_dataset.csv')\n",
    "\n",
    "# Selecionando os dados\n",
    "MSI = MSI_load.iloc[:, 1:].T\n",
    "\n",
    "# removendo colunas extras\n",
    "MSI = MSI.drop(\"Wave\", axis=0)\n",
    "\n",
    "# Nomeando as bandas de acordo com seu comprimento de onda central\n",
    "MSI.columns = ['443', '492', '560', '665', '704', '740', '783', '833', '865']\n",
    "\n",
    "# Criando uma coluna para o nome da cada ponto\n",
    "MSI[\"GLORIA_ID\"]  = MSI.index\n",
    "MSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dae3f4-cdaa-4516-9137-8349db96859d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T16:00:14.186903Z",
     "iopub.status.busy": "2025-05-31T16:00:14.185766Z",
     "iopub.status.idle": "2025-05-31T16:00:15.873874Z",
     "shell.execute_reply": "2025-05-31T16:00:15.873236Z",
     "shell.execute_reply.started": "2025-05-31T16:00:14.186873Z"
    }
   },
   "outputs": [],
   "source": [
    "#[CODE - Merge and Plot]\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def process_gloria_data(meta_and_lab, msi_data, \n",
    "                       chla_max=1000, chla_min=0,\n",
    "                       ndci_min=0, ndci_max=2):\n",
    "    ## Merge with water quality, lat long (By GLORIA_ID)\n",
    "    # Select specific columns from meta_and_lab (equivalent to R's select)\n",
    "    meta_selected = meta_and_lab[['GLORIA_ID', 'TSS', 'Latitude', 'Longitude']]\n",
    "    \n",
    "    # Merge datasets (equivalent to R's merge)\n",
    "    merged = pd.merge(meta_selected, msi_data, on='GLORIA_ID', how='inner')\n",
    "    \n",
    "    merged = merged[merged['TSS'].notna()]\n",
    "    \n",
    "    return merged\n",
    "\n",
    "def plot_correlation_chart(data, columns=['TSS','704'], \n",
    "                          figsize=(10, 8), method='pearson'):\n",
    "    # Select only the specified columns\n",
    "    corr_data = data[columns]\n",
    "    \n",
    "    # Create correlation matrix\n",
    "    corr_matrix = corr_data.corr(method=method)\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=figsize)\n",
    "    \n",
    "    # Upper triangle: Correlation coefficients\n",
    "    mask_upper = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "    \n",
    "    # Lower triangle: Scatter plots\n",
    "    for i in range(len(columns)):\n",
    "        for j in range(len(columns)):\n",
    "            if i == j:\n",
    "                # Diagonal: Histograms\n",
    "                axes[i, j].hist(corr_data.iloc[:, i], bins=20, alpha=0.7, color='skyblue')\n",
    "                axes[i, j].set_title(f'{columns[i]} Distribution')\n",
    "                axes[i, j].set_ylabel('Frequency')\n",
    "            elif i > j:\n",
    "                # Lower triangle: Scatter plots\n",
    "                axes[i, j].scatter(corr_data.iloc[:, j], corr_data.iloc[:, i], \n",
    "                                 alpha=0.6, s=30)\n",
    "                axes[i, j].set_xlabel(columns[j])\n",
    "                axes[i, j].set_ylabel(columns[i])\n",
    "                \n",
    "                # Add trend line\n",
    "                z = np.polyfit(corr_data.iloc[:, j], corr_data.iloc[:, i], 1)\n",
    "                p = np.poly1d(z)\n",
    "                axes[i, j].plot(corr_data.iloc[:, j], p(corr_data.iloc[:, j]), \n",
    "                               \"r--\", alpha=0.8)\n",
    "            else:\n",
    "                # Upper triangle: Correlation coefficients\n",
    "                corr_val = corr_matrix.iloc[i, j]\n",
    "                axes[i, j].text(0.5, 0.5, f'r = {corr_val:.3f}', \n",
    "                               transform=axes[i, j].transAxes,\n",
    "                               fontsize=16, ha='center', va='center')\n",
    "                axes[i, j].set_xlim(0, 1)\n",
    "                axes[i, j].set_ylim(0, 1)\n",
    "                axes[i, j].set_xticks([])\n",
    "                axes[i, j].set_yticks([])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def simple_correlation_plot(data, x_col='TSS', y_col='704', figsize=(8, 6)):   \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    # Create scatter plot\n",
    "    ax.scatter(data[x_col], data[y_col], alpha=0.6, s=50)\n",
    "    \n",
    "    # Add trend line\n",
    "    z = np.polyfit(data[x_col], data[y_col], 1)\n",
    "    p = np.poly1d(z)\n",
    "    ax.plot(data[x_col], p(data[x_col]), \"r--\", alpha=0.8, linewidth=2)\n",
    "    \n",
    "    # Calculate correlation\n",
    "    corr_coeff, p_value = pearsonr(data[x_col], data[y_col])\n",
    "    \n",
    "    # Add correlation info to plot\n",
    "    ax.text(0.05, 0.95, f'r = {corr_coeff:.3f}\\np = {p_value:.3f}', \n",
    "            transform=ax.transAxes, fontsize=12,\n",
    "            verticalalignment='top', \n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    ax.set_xlabel(x_col, fontsize=12)\n",
    "    ax.set_ylabel(y_col, fontsize=12)\n",
    "    ax.set_title(f'{y_col} vs {x_col}', fontsize=14)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    return fig, ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64584155-3476-4241-ba23-477d09e8d9b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T16:00:25.774990Z",
     "iopub.status.busy": "2025-05-31T16:00:25.774373Z",
     "iopub.status.idle": "2025-05-31T16:00:25.861147Z",
     "shell.execute_reply": "2025-05-31T16:00:25.860602Z",
     "shell.execute_reply.started": "2025-05-31T16:00:25.774963Z"
    }
   },
   "outputs": [],
   "source": [
    "meta_and_lab = pd.read_csv(\"Data/GLORIA_2022/GLORIA_meta_and_lab.csv\")\n",
    "meta_and_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62969e0e-51f2-4127-8373-b4c1a69752f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T16:00:36.338033Z",
     "iopub.status.busy": "2025-05-31T16:00:36.337399Z",
     "iopub.status.idle": "2025-05-31T16:00:37.052320Z",
     "shell.execute_reply": "2025-05-31T16:00:37.051661Z",
     "shell.execute_reply.started": "2025-05-31T16:00:36.338006Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lendo os dados\n",
    "meta_and_lab = pd.read_csv(\"Data/GLORIA_2022/GLORIA_meta_and_lab.csv\")\n",
    "\n",
    "# Pré-processando os dados (reoganização de colunas e concatenando as tabelas)\n",
    "merged = process_gloria_data(meta_and_lab, MSI)\n",
    "\n",
    "# Informações após reoganização\n",
    "print(f\"Original data: {len(meta_and_lab)} rows\")\n",
    "print(f\"After processing: {len(merged)} rows\")\n",
    "\n",
    "# Graficos de avaliação\n",
    "fig2 = plot_correlation_chart(merged)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afcd3d3-fc17-43d3-94b9-6b1e961838cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T19:44:04.666532Z",
     "iopub.status.busy": "2025-05-30T19:44:04.665966Z",
     "iopub.status.idle": "2025-05-30T19:44:04.738622Z",
     "shell.execute_reply": "2025-05-30T19:44:04.737930Z",
     "shell.execute_reply.started": "2025-05-30T19:44:04.666509Z"
    }
   },
   "outputs": [],
   "source": [
    "# Salvando os dados em csv \n",
    "merged.to_csv('Outputs/sentinel2_simulated_filtered_TSS.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "966c3b58-c2ff-4c0e-a203-d6a9b1be150c",
   "metadata": {},
   "source": [
    "# Modelo Random Forest para Sólidos Totais em Suspenssão\n",
    "<hr style=\"border:1px solid #0077b9;\">\n",
    "\n",
    "Agora que nós já fizemos as primeiras organizações nos dados, podemos começar a fazer um treinamento e validação de um algoritmo de Random Forest com os dados de campo simulados\n",
    "\n",
    "Este código irá utilizar os dados organizados anteriormente para gerar um algoritmo de árvores de decisão para estimativa da concentração de Sólidos Totais em Suspenssão .\n",
    "\n",
    "Este código é apenas um exemplo. Idealmente, deveríamos validar o modelo aplicado na imagem em dados coletados ao mesmo tempo da passagem do satélite.\n",
    "\n",
    "Como estes dados não estão disponíveis, iremos treinar e validar utilizando apenas os dados de campo do GLORIA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847f0679-a11b-4820-a054-980d1a39f4d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T16:01:02.080166Z",
     "iopub.status.busy": "2025-05-31T16:01:02.079474Z",
     "iopub.status.idle": "2025-05-31T16:01:02.488720Z",
     "shell.execute_reply": "2025-05-31T16:01:02.488122Z",
     "shell.execute_reply.started": "2025-05-31T16:01:02.080141Z"
    }
   },
   "outputs": [],
   "source": [
    "# [CODE - Funções e plots]\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Calculando as métricas de erro\n",
    "def calculate_metrics(y_true, y_pred, dataset_name):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\n{dataset_name} Metrics:\")\n",
    "    print(f\"RMSE: {rmse:.3f}\")\n",
    "    print(f\"MAE: {mae:.3f}\")\n",
    "    print(f\"R²: {r2:.3f}\")\n",
    "    \n",
    "    return rmse, mae, r2\n",
    "\n",
    "# Gráficos do Random Forest\n",
    "def plot_rf_results(y_train, y_train_pred, y_test, y_test_pred, \n",
    "                   train_r2, train_rmse, test_r2, test_rmse, \n",
    "                   feature_importance, target_name='TSS'):\n",
    "    \"\"\"\n",
    "    Plot Random Forest model results including training/test performance,\n",
    "    feature importance, and residuals.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_train, y_train_pred : array-like\n",
    "        Training observed and predicted values\n",
    "    y_test, y_test_pred : array-like  \n",
    "        Test observed and predicted values\n",
    "    train_r2, train_rmse : float\n",
    "        Training set R² and RMSE metrics\n",
    "    test_r2, test_rmse : float\n",
    "        Test set R² and RMSE metrics\n",
    "    feature_importance : DataFrame\n",
    "        DataFrame with 'Feature' and 'Importance' columns\n",
    "    target_name : str\n",
    "        Name of target variable for plot labels\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. Training set: Predicted vs Observed\n",
    "    axes[0, 0].scatter(y_train, y_train_pred, alpha=0.6, s=20)\n",
    "    axes[0, 0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', lw=2)\n",
    "    axes[0, 0].set_xlabel(f'Observed {target_name}')\n",
    "    axes[0, 0].set_ylabel(f'Predicted {target_name}')\n",
    "    axes[0, 0].set_title(f'Training Set\\nR² = {train_r2:.3f}, RMSE = {train_rmse:.3f}')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Test set: Predicted vs Observed\n",
    "    axes[0, 1].scatter(y_test, y_test_pred, alpha=0.6, s=20, color='orange')\n",
    "    axes[0, 1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "    axes[0, 1].set_xlabel(f'Observed {target_name}')\n",
    "    axes[0, 1].set_ylabel(f'Predicted {target_name}')\n",
    "    axes[0, 1].set_title(f'Test Set\\nR² = {test_r2:.3f}, RMSE = {test_rmse:.3f}')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Feature importance plot\n",
    "    axes[1, 0].barh(feature_importance['Feature'], feature_importance['Importance'])\n",
    "    axes[1, 0].set_xlabel('Feature Importance')\n",
    "    axes[1, 0].set_title('Random Forest Feature Importance')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Residuals plot\n",
    "    residuals_test = y_test - y_test_pred\n",
    "    axes[1, 1].scatter(y_test_pred, residuals_test, alpha=0.6, s=20, color='green')\n",
    "    axes[1, 1].axhline(y=0, color='r', linestyle='--')\n",
    "    axes[1, 1].set_xlabel(f'Predicted {target_name}')\n",
    "    axes[1, 1].set_ylabel('Residuals')\n",
    "    axes[1, 1].set_title('Residuals Plot (Test Set)')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbec2bb-91f7-44ca-8d79-fe2a889d251b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T16:01:02.490227Z",
     "iopub.status.busy": "2025-05-31T16:01:02.489845Z",
     "iopub.status.idle": "2025-05-31T16:01:02.508464Z",
     "shell.execute_reply": "2025-05-31T16:01:02.507964Z",
     "shell.execute_reply.started": "2025-05-31T16:01:02.490207Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import seaborn as sns\n",
    "\n",
    "# Lendo os dados\n",
    "data = pd.read_csv(\"Outputs/sentinel2_simulated_filtered_TSS.csv\")\n",
    "print(f\"Original data shape: {data.shape}\")\n",
    "print(f\"Column names: {list(data.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487e4797-afa9-4f8e-84d9-b7b063cdc561",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T16:01:06.490073Z",
     "iopub.status.busy": "2025-05-31T16:01:06.489314Z",
     "iopub.status.idle": "2025-05-31T16:01:10.607283Z",
     "shell.execute_reply": "2025-05-31T16:01:10.606653Z",
     "shell.execute_reply.started": "2025-05-31T16:01:06.490050Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(13)\n",
    "\n",
    "# Definindo as bandas a serem utilizadas\n",
    "wavelength_bands = ['443', '492', '560', '665', '704', '740', '783', '833', '865']\n",
    "print(f\"Usando as bandas: {wavelength_bands}\")\n",
    "\n",
    "# Filtrando os dados\n",
    "data_clean = data.dropna(subset=wavelength_bands + ['TSS']).copy()\n",
    "print(f\"Limpando NaNs dos dados: {data_clean.shape}\")\n",
    "\n",
    "# Filtrando valores excessivos (Opcional)\n",
    "tss_lower, tss_upper = 0.1, 300  # Adjust based on your data range\n",
    "data_filtered = data_clean[(data_clean['TSS'] >= tss_lower) & \n",
    "                          (data_clean['TSS'] <= tss_upper)].copy()\n",
    "print(f\"Filtrando valores entre: {tss_lower}-{tss_upper}): {data_filtered.shape}\")\n",
    "\n",
    "# Separando os dados de X e y\n",
    "X = data_filtered[wavelength_bands].copy()\n",
    "y = data_filtered['TSS'].copy()\n",
    "\n",
    "print(f\"Formato Variáveis preditivas: {X.shape}\")\n",
    "print(f\"Formato Variável alvo: {y.shape}\")\n",
    "\n",
    "# Criando o conjunto de train/test (70/30)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=13)\n",
    "\n",
    "print(f\"Treinamento - X: {X_train.shape}, y: {y_train.shape}\")\n",
    "print(f\"Teste - X: {X_test.shape}, y: {y_test.shape}\")\n",
    "\n",
    "# Estatísticas\n",
    "print(f\"\\nestatisticas para a variável alvo (TSS):\")\n",
    "print(f\"Treinamento - Média: {y_train.mean():.3f}, Std: {y_train.std():.3f}\")\n",
    "print(f\"Teste - Média: {y_test.mean():.3f}, Std: {y_test.std():.3f}\")\n",
    "\n",
    "# Modelo Random Forest\n",
    "print(\"\\n## Treinando o Modelo Random Forest\")\n",
    "\n",
    "# Variável com as Configurações do RF\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=300,        # Número de arvores\n",
    "    max_depth=40,           # Maxima profundidade das arvores\n",
    "    min_samples_split=20,    # Minimo de amostras em cada divisão\n",
    "    min_samples_leaf=4,     # Minimo de amostras em cada folha da arvore\n",
    "    random_state=13,        # Estado Pseudo_randômico\n",
    "    n_jobs=-1              # Usar todos os processadores\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(\"Modelo Random Forest treinado com sucesso!\")\n",
    "\n",
    "# Predição\n",
    "y_train_pred = rf_model.predict(X_train)\n",
    "y_test_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate and display metrics\n",
    "train_rmse, train_mae, train_r2 = calculate_metrics(y_train, y_train_pred, \"Training\")\n",
    "test_rmse, test_mae, test_r2 = calculate_metrics(y_test, y_test_pred, \"Test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f62ad21-f620-43f2-83f9-48883611f21c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T16:01:17.679533Z",
     "iopub.status.busy": "2025-05-31T16:01:17.678791Z",
     "iopub.status.idle": "2025-05-31T16:01:17.730458Z",
     "shell.execute_reply": "2025-05-31T16:01:17.729908Z",
     "shell.execute_reply.started": "2025-05-31T16:01:17.679511Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': wavelength_bands,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(f\"\\nFeature Importance:\")\n",
    "print(feature_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45d9551-a050-4671-91db-07cf5c2e8ee2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T16:01:24.562379Z",
     "iopub.status.busy": "2025-05-31T16:01:24.561749Z",
     "iopub.status.idle": "2025-05-31T16:01:25.118271Z",
     "shell.execute_reply": "2025-05-31T16:01:25.117688Z",
     "shell.execute_reply.started": "2025-05-31T16:01:24.562357Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plotar resultados\n",
    "plot_rf_results(y_train, y_train_pred, y_test, y_test_pred,\n",
    "               train_r2, train_rmse, test_r2, test_rmse, \n",
    "               feature_importance, target_name='TSS')\n",
    "\n",
    "# Resumo da performance do modelo\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"RESUMO DO MODELO RANDOM FOREST\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Características usadas: {len(wavelength_bands)} bandas Rrs\")\n",
    "print(f\"Amostras de treinamento: {X_train.shape[0]}\")\n",
    "print(f\"Amostras de teste: {X_test.shape[0]}\")\n",
    "print(f\"\")\n",
    "print(f\"Performance no Conjunto de Teste:\")\n",
    "print(f\"  Pontuação R²: {test_r2:.3f}\")\n",
    "print(f\"  RMSE: {test_rmse:.3f}\")\n",
    "print(f\"  MAE: {test_mae:.3f}\")\n",
    "print(f\"\")\n",
    "print(f\"Características mais importantes:\")\n",
    "for i, row in feature_importance.head(3).iterrows():\n",
    "    print(f\"  {row['Feature']}: {row['Importance']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcffccdd-6c28-4cc4-8f5d-32f7e35d5569",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T19:46:11.191254Z",
     "iopub.status.busy": "2025-05-30T19:46:11.190461Z",
     "iopub.status.idle": "2025-05-30T19:46:11.206409Z",
     "shell.execute_reply": "2025-05-30T19:46:11.205878Z",
     "shell.execute_reply.started": "2025-05-30T19:46:11.191228Z"
    }
   },
   "outputs": [],
   "source": [
    "# Salvar os resultados para CSV\n",
    "results_df = pd.DataFrame({\n",
    "    'Observed_TSS': y_test,\n",
    "    'Predicted_TSS': y_test_pred,\n",
    "    'Residuals': y_test - y_test_pred\n",
    "})\n",
    "results_df.to_csv('Outputs/rf_predictions.csv', index=False)\n",
    "print(f\"\\nPredictions saved to 'rf_predictions.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cf4e2d-c855-4756-88e2-359c2648c8aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T16:08:04.268956Z",
     "iopub.status.busy": "2025-05-31T16:08:04.268183Z",
     "iopub.status.idle": "2025-05-31T16:08:04.637480Z",
     "shell.execute_reply": "2025-05-31T16:08:04.636899Z",
     "shell.execute_reply.started": "2025-05-31T16:08:04.268933Z"
    }
   },
   "outputs": [],
   "source": [
    "# Salvar o modelo para posterior aplicação em imagens S2\n",
    "import joblib\n",
    "\n",
    "# Salvar o modelo\n",
    "joblib.dump(rf_model, 'Outputs/random_forest_tss_model.pkl')\n",
    "print(\"Modelo salvo como 'random_forest_tss_model.pkl'\")\n",
    "\n",
    "# Salvar nomes das características (importante para aplicação no S2)\n",
    "feature_names = ['443', '492', '560', '665', '704', '740', '783', '833', '865']\n",
    "joblib.dump(feature_names, 'Outputs/model_features.pkl')\n",
    "print(\"Características salvas como 'model_features.pkl'\")\n",
    "\n",
    "# Salvar metadados do modelo para referência\n",
    "model_metadata = {\n",
    "    'target_variable': 'TSS',\n",
    "    'n_features': len(feature_names),\n",
    "    'feature_names': feature_names,\n",
    "    'test_r2': test_r2,\n",
    "    'test_rmse': test_rmse,\n",
    "    'test_mae': test_mae,\n",
    "    'model_params': rf_model.get_params()\n",
    "}\n",
    "joblib.dump(model_metadata, 'Outputs/model_metadata.pkl')\n",
    "print(\"Metadados do modelo salvos como 'model_metadata.pkl'\")\n",
    "\n",
    "print(f\"\\nPara aplicar este modelo em imagens S2, você precisará:\")\n",
    "print(f\"1. Carregar modelo: rf_model = joblib.load('random_forest_tss_model.pkl')\")\n",
    "print(f\"2. Carregar características: features = joblib.load('model_features.pkl')\")\n",
    "print(f\"3. Garantir que as bandas Rrs do S2 correspondam às características de treinamento\")\n",
    "print(f\"4. Aplicar: predictions = rf_model.predict(s2_rrs_data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a092e7d6-fc58-4318-b052-3578810ee5a3",
   "metadata": {},
   "source": [
    "# Download de imagens L1C e Correção atmosférica para ambientes aquáticos\n",
    "<hr style=\"border:1px solid #0077b9;\">\n",
    "\n",
    "Para aplicar a correção do ACOLITE precisamos de duas coisas: Primeiro, precisamos baixar os bundles em nível 1 - sem correção atmosférica. Por sorte, o BDC fornece esses dados pra gente - o que facilita imensamente o acesso aos dados. \n",
    "\n",
    "Usaremos o pystac-client para fazer as buscas nos dados - \"imagem Sentinel-2/MSI\" na data anterior ao Evento () e após as enchentes na data de ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5babed7-39da-4b71-a063-006a795970dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T14:52:09.907375Z",
     "iopub.status.busy": "2025-05-31T14:52:09.906783Z",
     "iopub.status.idle": "2025-05-31T14:52:10.130428Z",
     "shell.execute_reply": "2025-05-31T14:52:10.129876Z",
     "shell.execute_reply.started": "2025-05-31T14:52:09.907350Z"
    }
   },
   "outputs": [],
   "source": [
    "from pystac_client import Client\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94a8a35-d594-41a2-bfb9-e18b86920cf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T14:59:40.648579Z",
     "iopub.status.busy": "2025-05-31T14:59:40.648253Z",
     "iopub.status.idle": "2025-05-31T14:59:40.729780Z",
     "shell.execute_reply": "2025-05-31T14:59:40.729191Z",
     "shell.execute_reply.started": "2025-05-31T14:59:40.648558Z"
    }
   },
   "outputs": [],
   "source": [
    "# Conectando ao catalogo STAC\n",
    "stac_obj = Client.open(\"https://data.inpe.br/bdc/stac/v1/\")\n",
    "\n",
    "# Parâmetros de Busca\n",
    "datas_antes = \"2024-04-18/2024-04-20\"\n",
    "datas_depois = \"2024-06-01/2024-06-03\"\n",
    "BBOX = [-51.33503, -30.39062, -51.01744, -30.00016]  # xmin, ymin, xmax, ymax\n",
    "\n",
    "\n",
    "# Buscando os Items\n",
    "search_obj = stac_obj.search(\n",
    "    collections=[\"S2_L1C_BUNDLE-1\"],\n",
    "    bbox=BBOX,\n",
    "    datetime=datas_antes,\n",
    ")\n",
    "items = list(search_obj.items())\n",
    "\n",
    "# Itens encontrados\n",
    "print(f\"Found {len(items)} items\")\n",
    "for i, item in enumerate(items):\n",
    "    print(f\"Item {i+1}: {item.id}\")\n",
    "    print(f\"  Date: {item.datetime}\"),\n",
    "    if 'eo:cloud_cover' in item.properties:\n",
    "        print(f\"  Cloud cover: {item.properties['eo:cloud_cover']}%\")\n",
    "\n",
    "\n",
    "items[0].assets['asset']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c32eac2-a579-4542-ba2d-d6d25a55f219",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T14:59:43.898424Z",
     "iopub.status.busy": "2025-05-31T14:59:43.898105Z",
     "iopub.status.idle": "2025-05-31T14:59:48.437603Z",
     "shell.execute_reply": "2025-05-31T14:59:48.436979Z",
     "shell.execute_reply.started": "2025-05-31T14:59:43.898391Z"
    }
   },
   "outputs": [],
   "source": [
    "# Baixar os items\n",
    "download_dir = 'Outputs'\n",
    "for item in items:\n",
    "    print(f\"Downloading: {item.id}\")\n",
    "    \n",
    "    # Pegando o link\n",
    "    download_url = items[0].assets['asset'].href\n",
    "    filename = f\"{item.id}.zip\"\n",
    "    filepath = os.path.join(download_dir, filename)\n",
    "    \n",
    "    # verificando se ja baixado\n",
    "    if os.path.exists(filepath):\n",
    "        print(f\"File already exists: {filename}\")\n",
    "        continue\n",
    "    \n",
    "    # Fazendo o download\n",
    "    response = requests.get(download_url, stream=True)\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    \n",
    "    with open(filepath, 'wb') as f, tqdm(desc=filename, total=total_size, unit='B', unit_scale=True) as pbar:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            size = f.write(chunk)\n",
    "            pbar.update(size)\n",
    "    \n",
    "    print(f\"Baixado a imagem: {filename}\")\n",
    "\n",
    "print(f\"\\nDownload completo! Arquivos salvos em: {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34796664-7409-45c8-b4b2-d8f0ddb98877",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T15:16:12.572924Z",
     "iopub.status.busy": "2025-05-31T15:16:12.572607Z",
     "iopub.status.idle": "2025-05-31T15:16:16.270101Z",
     "shell.execute_reply": "2025-05-31T15:16:16.269296Z",
     "shell.execute_reply.started": "2025-05-31T15:16:12.572902Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import zipfile\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Pasta com os ZIPs extraídos que será criada\n",
    "pasta_destino = Path(\"Outputs/Extraidos/\")\n",
    "pasta_destino.mkdir(parents=True, exist_ok=True)  # Se não existir, crio a pasta\n",
    "\n",
    "# Path base das imagens\n",
    "path_images = 'Outputs'\n",
    "\n",
    "# Aqui vou fazer a busca recursiva dos arquivos .ZIP .zip\n",
    "arquivos_zip = glob.glob(os.path.join(path_images, \"**\", \"*.zip\"), recursive=True)\n",
    "print(arquivos_zip)\n",
    "\n",
    "# Loop para extrair todos os .zip\n",
    "for zip_path in arquivos_zip:\n",
    "    nome_arquivo = Path(zip_path).stem  # Nome do zip sem extensão\n",
    "    print(nome_arquivo)\n",
    "    \n",
    "    # Extrair diretamente para a pasta destino (sem criar subpasta)\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(pasta_destino)  # Extrai diretamente para pasta_destino\n",
    "    \n",
    "    print(f\"Extraído: {zip_path} → {pasta_destino}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51a560a-32c9-4c38-a874-3eebea58c661",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T16:02:00.246928Z",
     "iopub.status.busy": "2025-05-31T16:02:00.246292Z",
     "iopub.status.idle": "2025-05-31T16:02:00.459475Z",
     "shell.execute_reply": "2025-05-31T16:02:00.458898Z",
     "shell.execute_reply.started": "2025-05-31T16:02:00.246902Z"
    }
   },
   "outputs": [],
   "source": [
    "# [CODE - Leitura das bandas da Imagem processada]\n",
    "\n",
    "import numpy as np\n",
    "from rasterio.windows import from_bounds, Window\n",
    "import rasterio\n",
    "from matplotlib import pyplot as plt\n",
    "from rasterio.warp import transform_bounds\n",
    "from rasterio.windows import transform as window_transform\n",
    "plt.rcParams['figure.figsize'] = (20, 10)\n",
    "\n",
    "def read_img(uri: str, bbox: tuple = None, bbox_crs: str = \"EPSG:4326\", masked: bool = True):\n",
    "    \"\"\"Read raster window as numpy.ma.masked_array.\"\"\"\n",
    "    with rasterio.open(uri) as src:\n",
    "        if bbox is not None:\n",
    "            # reprojeta o bbox para o CRS do raster\n",
    "            projected_bbox = transform_bounds(bbox_crs, src.crs, *bbox)\n",
    "            window = from_bounds(*projected_bbox, transform=src.transform)\n",
    "            data = src.read(window=window, masked=masked)\n",
    "            new_transform = rasterio.windows.transform(window, src.transform)\n",
    "\n",
    "            profile = src.profile.copy()\n",
    "            profile.update({\n",
    "                \"height\": window.height,\n",
    "                \"width\": window.width,\n",
    "                \"transform\": new_transform\n",
    "            })\n",
    "        else:\n",
    "            data = src.read(masked=masked)\n",
    "            profile = src.profile\n",
    "\n",
    "    return data, profile\n",
    "\n",
    "def normalize_and_adjust_brightness(array, brightness_factor=1):\n",
    "    \"\"\"Normalizes numpy arrays into scale 0.0 - 1.0\"\"\"\n",
    "    array_min, array_max = array.min(), array.max()\n",
    "    normalized = (array - array_min) / (array_max - array_min)\n",
    "    brightened = np.clip(normalized * brightness_factor, 0.0, 1.0)\n",
    "    return brightened\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cab7e4-2a6c-4702-bfd2-4ef1928e4854",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T15:46:15.584667Z",
     "iopub.status.busy": "2025-05-31T15:46:15.583929Z",
     "iopub.status.idle": "2025-05-31T15:46:27.443578Z",
     "shell.execute_reply": "2025-05-31T15:46:27.442971Z",
     "shell.execute_reply.started": "2025-05-31T15:46:15.584640Z"
    }
   },
   "outputs": [],
   "source": [
    "b2 = 'Outputs/Extraidos/S2A_MSIL1C_20240418T132241_N0510_R038_T22JDM_20240418T164038.SAFE/GRANULE/L1C_T22JDM_A046081_20240418T132235/IMG_DATA/T22JDM_20240418T132241_B02.jp2'\n",
    "b3 = 'Outputs/Extraidos/S2A_MSIL1C_20240418T132241_N0510_R038_T22JDM_20240418T164038.SAFE/GRANULE/L1C_T22JDM_A046081_20240418T132235/IMG_DATA/T22JDM_20240418T132241_B03.jp2'\n",
    "b4 = 'Outputs/Extraidos/S2A_MSIL1C_20240418T132241_N0510_R038_T22JDM_20240418T164038.SAFE/GRANULE/L1C_T22JDM_A046081_20240418T132235/IMG_DATA/T22JDM_20240418T132241_B04.jp2'\n",
    "\n",
    "BBOX = [-51.33503, -30.39062, -51.01744, -30.00016]\n",
    "b02_image, _ = read_img(b2,BBOX)\n",
    "b03_image, _ = read_img(b3,BBOX)\n",
    "b04_image, _ = read_img(b4,BBOX)\n",
    "\n",
    "rgb_normalized_stack = np.dstack((\n",
    "    normalize_and_adjust_brightness(b04_image[0], 8.5), \n",
    "    normalize_and_adjust_brightness(b03_image[0], 10.5), \n",
    "    normalize_and_adjust_brightness(b02_image[0], 8.5)))\n",
    "plt.imshow(rgb_normalized_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3446d1b3-c4ac-4b44-b944-cb8f7f5ac127",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T15:46:27.444975Z",
     "iopub.status.busy": "2025-05-31T15:46:27.444469Z",
     "iopub.status.idle": "2025-05-31T15:46:40.495810Z",
     "shell.execute_reply": "2025-05-31T15:46:40.495272Z",
     "shell.execute_reply.started": "2025-05-31T15:46:27.444952Z"
    }
   },
   "outputs": [],
   "source": [
    "b2 = 'Outputs/Extraidos/S2B_MSIL1C_20240602T132239_N0510_R038_T22JDM_20240602T134842.SAFE/GRANULE/L1C_T22JDM_A037816_20240602T132233/IMG_DATA/T22JDM_20240602T132239_B02.jp2'\n",
    "b3 = 'Outputs/Extraidos/S2B_MSIL1C_20240602T132239_N0510_R038_T22JDM_20240602T134842.SAFE/GRANULE/L1C_T22JDM_A037816_20240602T132233/IMG_DATA/T22JDM_20240602T132239_B03.jp2'\n",
    "b4 = 'Outputs/Extraidos/S2B_MSIL1C_20240602T132239_N0510_R038_T22JDM_20240602T134842.SAFE/GRANULE/L1C_T22JDM_A037816_20240602T132233/IMG_DATA/T22JDM_20240602T132239_B04.jp2'\n",
    "\n",
    "BBOX = [-51.33503, -30.39062, -51.01744, -30.00016]\n",
    "b02_image, _ = read_img(b2,BBOX)\n",
    "b03_image, _ = read_img(b3,BBOX)\n",
    "b04_image, _ = read_img(b4,BBOX)\n",
    "\n",
    "rgb_normalized_stack = np.dstack((\n",
    "    normalize_and_adjust_brightness(b04_image[0], 6.5), \n",
    "    normalize_and_adjust_brightness(b03_image[0], 10.5), \n",
    "    normalize_and_adjust_brightness(b02_image[0], 10.5)))\n",
    "plt.imshow(rgb_normalized_stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6796370-8f12-4233-b485-2b3007ae1316",
   "metadata": {},
   "source": [
    "<img src=\"https://camo.githubusercontent.com/819c228f84e8da719975991335b2cd2fc045dc0b182adee76f7c3277c2f3259e/68747470733a2f2f6173736574732e6769736875622e6f72672f696d616765732f6879706572636f6173745f6c6f676f5f3630302e706e67\" align=\"right\" width=\"200\"/>\n",
    "\n",
    "# Rodar o ACOLITE em Python \n",
    "---\n",
    "\n",
    "\n",
    "Para rodar o ACOLITE iremos utilizar como auxílio o pacote hypercoast, que é um pacote desenvolvido por Bingqing Liu e Qiusheng Wu (disponível em: https://hypercoast.org/#license). Ele é feito inicialmente para trabalhar com dados hiperesepctrais de sensoriamento remoto - mas com diversas aplicações importantes com dados multiespectrais - incluindo maneiras mais simples de instalar o ACOLITE e rodar ele em ambiente Jupyter Notebook - o que não é totalmente trivial. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905010de-4086-4645-9bd6-3768ec855b23",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-30T13:51:15.879643Z",
     "iopub.status.busy": "2025-05-30T13:51:15.878922Z",
     "iopub.status.idle": "2025-05-30T13:53:15.274937Z",
     "shell.execute_reply": "2025-05-30T13:53:15.274256Z",
     "shell.execute_reply.started": "2025-05-30T13:51:15.879620Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Se você ainda não rodou este comando, você vai precisar baixar  o ACOLITE e instalar o HYPERCOAST!!!!!! Desmarque o # nessa linha\n",
    "\n",
    "\n",
    "#!git clone --depth 1 https://github.com/acolite/acolite\n",
    "#!pip install \"hypercoast[extra]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1700de-6f55-45bb-b130-b2ab81d34e89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T16:14:28.765067Z",
     "iopub.status.busy": "2025-05-31T16:14:28.764119Z",
     "iopub.status.idle": "2025-05-31T16:14:31.083507Z",
     "shell.execute_reply": "2025-05-31T16:14:31.082915Z",
     "shell.execute_reply.started": "2025-05-31T16:14:28.765041Z"
    }
   },
   "outputs": [],
   "source": [
    "import hypercoast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b26181-2967-4499-b86c-33b5ebde4d20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T16:14:31.084821Z",
     "iopub.status.busy": "2025-05-31T16:14:31.084392Z",
     "iopub.status.idle": "2025-05-31T16:14:31.108494Z",
     "shell.execute_reply": "2025-05-31T16:14:31.107987Z",
     "shell.execute_reply.started": "2025-05-31T16:14:31.084800Z"
    }
   },
   "outputs": [],
   "source": [
    "acolite_dir = hypercoast.download_acolite('Scripts/acolite/')\n",
    "out_dir = os.path.join('Outputs', \"acolite_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68012378-3366-4acb-83ea-0ece39f4bbb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T15:17:05.298804Z",
     "iopub.status.busy": "2025-05-31T15:17:05.298037Z",
     "iopub.status.idle": "2025-05-31T15:17:05.303313Z",
     "shell.execute_reply": "2025-05-31T15:17:05.302802Z",
     "shell.execute_reply.started": "2025-05-31T15:17:05.298778Z"
    }
   },
   "outputs": [],
   "source": [
    "input_dir = os.path.join('Outputs/', \"Extraidos\")\n",
    "input_files = [os.path.join(input_dir, f) for f in os.listdir(input_dir)]\n",
    "input_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f224c3-6434-488b-acb6-652b06f4e2db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T15:17:10.608786Z",
     "iopub.status.busy": "2025-05-31T15:17:10.607889Z",
     "iopub.status.idle": "2025-05-31T15:25:59.487469Z",
     "shell.execute_reply": "2025-05-31T15:25:59.486656Z",
     "shell.execute_reply.started": "2025-05-31T15:17:10.608761Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in input_files:\n",
    "\n",
    "#     output_dir = str.replace(i, 'Extraidos', \"ACOLITE\")\n",
    "    \n",
    "#     hypercoast.run_acolite(\n",
    "#         acolite_dir=acolite_dir,\n",
    "#         input_file=i,\n",
    "#         out_dir=output_dir,\n",
    "#         l2w_parameters=\"Rrs_*\",\n",
    "#         rgb_rhot=True,\n",
    "#         rgb_rhos=True,\n",
    "#         map_l2w=True,\n",
    "#         polygon = 'Data/Area_Lago_Guaiba.geojson', #Polígono do lago\n",
    "#         l2w_export_geotiff = True) # Exporta o L2W em Geotiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ba0485-8010-4cf3-92f8-f22c95efc3a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T16:09:16.728710Z",
     "iopub.status.busy": "2025-05-31T16:09:16.728098Z",
     "iopub.status.idle": "2025-05-31T16:09:21.316885Z",
     "shell.execute_reply": "2025-05-31T16:09:21.316204Z",
     "shell.execute_reply.started": "2025-05-31T16:09:16.728686Z"
    }
   },
   "outputs": [],
   "source": [
    "b3 = 'Outputs/ACOLITE/S2A_MSIL1C_20240418T132241_N0510_R038_T22JDM_20240418T164038.SAFE/S2A_MSI_2024_04_18_13_30_54_T22JDM_L2W_Rrs_443.tif'\n",
    "b4 = 'Outputs/ACOLITE/S2A_MSIL1C_20240418T132241_N0510_R038_T22JDM_20240418T164038.SAFE/S2A_MSI_2024_04_18_13_30_54_T22JDM_L2W_Rrs_560.tif'\n",
    "b5 = 'Outputs/ACOLITE/S2A_MSIL1C_20240418T132241_N0510_R038_T22JDM_20240418T164038.SAFE/S2A_MSI_2024_04_18_13_30_54_T22JDM_L2W_Rrs_665.tif'\n",
    "\n",
    "b03_image, _ = read_img(b3)\n",
    "b04_image, _ = read_img(b4)\n",
    "b05_image, _ = read_img(b5)\n",
    "\n",
    "rgb_normalized_stack = np.dstack((\n",
    "    normalize_and_adjust_brightness(b05_image[0], 1.5), \n",
    "    normalize_and_adjust_brightness(b04_image[0], 1.5), \n",
    "    normalize_and_adjust_brightness(b03_image[0], 1.5)))\n",
    "plt.imshow(rgb_normalized_stack)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbec4ac8-8597-4449-b581-38f2e867ebf0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-29T21:38:12.106411Z"
    }
   },
   "source": [
    "# Aplicação do modelo de TSS e comparação entre as datas\n",
    "---\n",
    "\n",
    "Agora que conseguimos executar a correção atmosférica com o ACOLITE, podemos aplicar o modelo de TSS nas imagens e avaliar os resultados para as duas datas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9814a8d0-6571-4b63-bfba-125fc8c2d63e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T16:02:22.764297Z",
     "iopub.status.busy": "2025-05-31T16:02:22.763289Z",
     "iopub.status.idle": "2025-05-31T16:02:23.491955Z",
     "shell.execute_reply": "2025-05-31T16:02:23.491351Z",
     "shell.execute_reply.started": "2025-05-31T16:02:22.764266Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import warnings\n",
    "import joblib\n",
    "import pickle\n",
    "from rasterio.plot import show\n",
    "from rasterio.warp import reproject, Resampling\n",
    "from rasterio.transform import from_bounds\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['figure.figsize'] = (20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a608e495-7b8e-4372-b186-4138d6fd7b90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T16:02:23.493208Z",
     "iopub.status.busy": "2025-05-31T16:02:23.492788Z",
     "iopub.status.idle": "2025-05-31T16:02:23.495991Z",
     "shell.execute_reply": "2025-05-31T16:02:23.495512Z",
     "shell.execute_reply.started": "2025-05-31T16:02:23.493188Z"
    }
   },
   "outputs": [],
   "source": [
    "caminho_img_anterior = 'Outputs/ACOLITE/S2A_MSIL1C_20240418T132241_N0510_R038_T22JDM_20240418T164038.SAFE'\n",
    "\n",
    "caminho_img_depois =  'Outputs/ACOLITE/S2B_MSIL1C_20240602T132239_N0510_R038_T22JDM_20240602T134842.SAFE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85754038-e702-435a-9115-3dcbff236739",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T16:02:25.859554Z",
     "iopub.status.busy": "2025-05-31T16:02:25.858958Z",
     "iopub.status.idle": "2025-05-31T16:02:25.869687Z",
     "shell.execute_reply": "2025-05-31T16:02:25.869144Z",
     "shell.execute_reply.started": "2025-05-31T16:02:25.859531Z"
    }
   },
   "outputs": [],
   "source": [
    "# [CODE - Carregar as imagens]\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "def load_s2_for_rf(image_path, model_path='Outputs/random_forest_tss_model.pkl', features_path='Outputs/model_features.pkl',sensor='S2A'):\n",
    "    \"\"\"\n",
    "    Load Sentinel-2 Rrs bands and prepare them for Random Forest prediction.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    image_path : str\n",
    "        Path to folder containing Rrs band files\n",
    "    model_path : str\n",
    "        Path to saved Random Forest model (default: 'random_forest_tss_model.pkl')\n",
    "    features_path : str\n",
    "        Path to saved model features (default: 'model_features.pkl')\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    rrs_reshaped : numpy.ndarray\n",
    "        Reshaped Rrs data ready for RF prediction (pixels, bands)\n",
    "    valid_mask : numpy.ndarray\n",
    "        Boolean mask for valid pixels\n",
    "    spatial_info : dict\n",
    "        Dictionary containing profile, transform, crs, height, width for output\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the trained model and required features\n",
    "    rf_model = joblib.load(model_path)\n",
    "    model_features = joblib.load(features_path)\n",
    "    if sensor == 'S2B':\n",
    "     model_features = ['442', '492', '559', '665', '704', '739', '780', '833', '864']\n",
    "    print(f\"Model expects these wavelengths: {model_features}\")\n",
    "    \n",
    "    # Find all Rrs band files\n",
    "    rrs_pattern = os.path.join(image_path, \"*_Rrs_*.tif\")\n",
    "    rrs_files = glob.glob(rrs_pattern)\n",
    "    print(f\"Found {len(rrs_files)} Rrs bands:\")\n",
    "    for file in rrs_files:\n",
    "        print(f\"  - {os.path.basename(file)}\")\n",
    "    \n",
    "    # Load bands in the order required by the model\n",
    "    rrs_bands_ordered = []\n",
    "    available_wavelengths = []\n",
    "    \n",
    "    for required_wavelength in model_features:\n",
    "        # Look for file with this wavelength\n",
    "        wavelength_found = False\n",
    "        \n",
    "        for rrs_file in rrs_files:\n",
    "            # Extract wavelength from filename (e.g., \"Rrs_665.tif\" -> \"665\") \n",
    "            file_wavelength = os.path.basename(rrs_file).split('_Rrs_')[1].split('.tif')[0]\n",
    "            \n",
    "            if file_wavelength == required_wavelength:\n",
    "                print(f\"✓ Loading {required_wavelength}nm from {os.path.basename(rrs_file)}\")\n",
    "                \n",
    "                with rasterio.open(rrs_file) as src:\n",
    "                    band_data = src.read(1)\n",
    "                    rrs_bands_ordered.append(band_data)\n",
    "                    available_wavelengths.append(required_wavelength)\n",
    "                    \n",
    "                    # Save spatial info from first band\n",
    "                    if len(rrs_bands_ordered) == 1:\n",
    "                        profile = src.profile\n",
    "                        transform = src.transform\n",
    "                        crs = src.crs\n",
    "                        height, width = band_data.shape\n",
    "                \n",
    "                wavelength_found = True\n",
    "                break\n",
    "        \n",
    "        if not wavelength_found:\n",
    "            print(f\"✗ Missing required wavelength: {required_wavelength}nm\")\n",
    "    \n",
    "    # Check if we have all required bands\n",
    "    if len(rrs_bands_ordered) != len(model_features):\n",
    "        print(f\"Warning: Missing {len(model_features) - len(rrs_bands_ordered)} required bands!\")\n",
    "        print(f\"Available: {available_wavelengths}\")\n",
    "        print(f\"Required: {model_features}\")\n",
    "        raise ValueError(\"Not all required wavelength bands are available!\")\n",
    "    \n",
    "    # Stack bands in correct order for RF model\n",
    "    rrs_stack = np.stack(rrs_bands_ordered, axis=0)  # Shape: (n_bands, height, width)\n",
    "    print(f\"Rrs stack shape: {rrs_stack.shape}\")\n",
    "    \n",
    "    # Reshape for model prediction: (pixels, bands)\n",
    "    n_bands, height, width = rrs_stack.shape\n",
    "    rrs_reshaped = rrs_stack.reshape(n_bands, -1).T  # Shape: (n_pixels, n_bands)\n",
    "    print(f\"Reshaped for prediction: {rrs_reshaped.shape}\")\n",
    "    \n",
    "    # Create mask for valid pixels (no NaN or negative values)\n",
    "    valid_mask = np.all(np.isfinite(rrs_reshaped) & (rrs_reshaped >= 0), axis=1)\n",
    "    print(f\"Valid pixels: {valid_mask.sum()}/{len(valid_mask)} ({100*valid_mask.mean():.1f}%)\")\n",
    "    \n",
    "    # Package spatial information\n",
    "    spatial_info = {\n",
    "        'profile': profile,\n",
    "        'transform': transform,\n",
    "        'crs': crs,\n",
    "        'height': height,\n",
    "        'width': width\n",
    "    }\n",
    "    \n",
    "    print(f\"Data ready for Random Forest prediction!\")\n",
    "    \n",
    "    return rrs_reshaped, valid_mask, spatial_info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b038a0df-fb5f-4e25-9910-4969d897d1a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T16:02:28.754681Z",
     "iopub.status.busy": "2025-05-31T16:02:28.753919Z",
     "iopub.status.idle": "2025-05-31T16:02:30.890350Z",
     "shell.execute_reply": "2025-05-31T16:02:30.889712Z",
     "shell.execute_reply.started": "2025-05-31T16:02:28.754659Z"
    }
   },
   "outputs": [],
   "source": [
    "rrs_data_anterior, valid_mask_anterior, spatial_info_anterior = load_s2_for_rf(caminho_img_anterior,sensor='S2A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9007fa1a-29ab-49c0-8c31-5bad9e7fcaca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T16:02:46.543134Z",
     "iopub.status.busy": "2025-05-31T16:02:46.542339Z",
     "iopub.status.idle": "2025-05-31T16:02:48.592572Z",
     "shell.execute_reply": "2025-05-31T16:02:48.591950Z",
     "shell.execute_reply.started": "2025-05-31T16:02:46.543108Z"
    }
   },
   "outputs": [],
   "source": [
    "rrs_data_depois, valid_mask_depois, spatial_info_depois = load_s2_for_rf(caminho_img_depois,sensor='S2B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a4ff27-5338-4e00-8c36-f2d17d2b2fd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T15:50:39.530553Z",
     "iopub.status.busy": "2025-05-31T15:50:39.529779Z",
     "iopub.status.idle": "2025-05-31T15:50:39.534151Z",
     "shell.execute_reply": "2025-05-31T15:50:39.533672Z",
     "shell.execute_reply.started": "2025-05-31T15:50:39.530527Z"
    }
   },
   "outputs": [],
   "source": [
    "valid_mask_depois.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f87838b-281b-4481-8297-99105fa9da74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T16:02:54.464283Z",
     "iopub.status.busy": "2025-05-31T16:02:54.463639Z",
     "iopub.status.idle": "2025-05-31T16:02:54.474557Z",
     "shell.execute_reply": "2025-05-31T16:02:54.473865Z",
     "shell.execute_reply.started": "2025-05-31T16:02:54.464256Z"
    }
   },
   "outputs": [],
   "source": [
    "# [CODE - Aplicar o RF e plotar]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "def apply_rf_model(rrs_data, valid_mask, spatial_info):\n",
    "    \"\"\"\n",
    "    Apply Random Forest model to predict TSS.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    rrs_data : numpy.ndarray\n",
    "        Reshaped Rrs data from load_s2_for_rf\n",
    "    valid_mask : numpy.ndarray\n",
    "        Valid pixel mask from load_s2_for_rf\n",
    "    spatial_info : dict\n",
    "        Spatial information from load_s2_for_rf\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tss_map : numpy.ndarray\n",
    "        2D array with TSS predictions\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load model and apply\n",
    "    rf_model = joblib.load('Outputs/random_forest_tss_model.pkl')\n",
    "    \n",
    "    # Apply Random Forest model to predict TSS\n",
    "    tss_predictions = np.full(len(valid_mask), np.nan)\n",
    "    valid_predictions = rf_model.predict(rrs_data[valid_mask])\n",
    "    tss_predictions[valid_mask] = valid_predictions\n",
    "    \n",
    "    # Reshape to image\n",
    "    tss_map = tss_predictions.reshape(spatial_info['height'], spatial_info['width'])\n",
    "    \n",
    "    print(f\"TSS prediction complete!\")\n",
    "    valid_tss = tss_map[np.isfinite(tss_map)]\n",
    "    print(f\"TSS range: {valid_tss.min():.1f} - {valid_tss.max():.1f} mg/L\")\n",
    "    print(f\"Mean TSS: {valid_tss.mean():.1f} mg/L\")\n",
    "    \n",
    "    return tss_map\n",
    "\n",
    "def plot_tss_map(tss_map, title=\"TSS Map\"):\n",
    "    \"\"\"\n",
    "    Plot TSS map and histogram.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    tss_map : numpy.ndarray\n",
    "        2D TSS array from apply_rf_model\n",
    "    title : str\n",
    "        Title for the plot\n",
    "    \"\"\"\n",
    "    \n",
    "    valid_tss = tss_map[np.isfinite(tss_map)]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # TSS Map\n",
    "    vmin, vmax = 0, 125  # Fixed range 0-125 mg/L\n",
    "    im = axes[0].imshow(tss_map, cmap='RdYlBu_r', vmin=vmin, vmax=vmax)\n",
    "    axes[0].set_title(f'{title} (mg/L)')\n",
    "    axes[0].axis('off')\n",
    "    plt.colorbar(im, ax=axes[0], shrink=0.8)\n",
    "    \n",
    "    # Histogram\n",
    "    axes[1].hist(valid_tss, bins=50, alpha=0.7, edgecolor='black')\n",
    "    axes[1].set_xlabel('TSS (mg/L)')\n",
    "    axes[1].set_ylabel('Frequency')\n",
    "    axes[1].set_title('TSS Distribution')\n",
    "    axes[1].set_xlim(vmin, vmax)  # Limit histogram x-axis to 0-125\n",
    "    \n",
    "    # Add mean and median lines\n",
    "    mean_tss = valid_tss.mean()\n",
    "    median_tss = np.median(valid_tss)\n",
    "    \n",
    "    axes[1].axvline(mean_tss, color='red', linestyle='--', linewidth=2, \n",
    "                   label=f'Média: {mean_tss:.1f}')\n",
    "    axes[1].axvline(median_tss, color='blue', linestyle='--', linewidth=2, \n",
    "                   label=f'Mediana: {median_tss:.1f}')\n",
    "    \n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def save_tss_map(tss_map, spatial_info, output_path):\n",
    "    \"\"\"\n",
    "    Save TSS map as GeoTIFF.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    tss_map : numpy.ndarray\n",
    "        2D TSS array from apply_rf_model\n",
    "    spatial_info : dict\n",
    "        Spatial information from load_s2_for_rf\n",
    "    output_path : str\n",
    "        Path for output file\n",
    "    \"\"\"\n",
    "    \n",
    "    tss_profile = spatial_info['profile'].copy()\n",
    "    tss_profile.update({'count': 1, 'dtype': 'float32', 'nodata': np.nan})\n",
    "    \n",
    "    with rasterio.open(output_path, 'w', **tss_profile) as dst:\n",
    "        dst.write(tss_map.astype(np.float32), 1)\n",
    "    \n",
    "    print(f\"TSS map saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8724e448-9b2a-4477-bfd9-2bef90b14acc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T16:03:06.037737Z",
     "iopub.status.busy": "2025-05-31T16:03:06.037066Z",
     "iopub.status.idle": "2025-05-31T16:03:35.144774Z",
     "shell.execute_reply": "2025-05-31T16:03:35.144083Z",
     "shell.execute_reply.started": "2025-05-31T16:03:06.037712Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply RF model\n",
    "tss_map_anterior = apply_rf_model(rrs_data_anterior, valid_mask_anterior, spatial_info_anterior)\n",
    "\n",
    "# Save the image\n",
    "save_tss_map(tss_map_anterior, spatial_info_anterior, \"Outputs/tss_anterior.tif\")\n",
    "\n",
    "# Plot results\n",
    "plot_tss_map(tss_map_anterior, \"TSS Anterior\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa692df-74eb-427d-a859-601d22967872",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T16:04:02.587827Z",
     "iopub.status.busy": "2025-05-31T16:04:02.587614Z",
     "iopub.status.idle": "2025-05-31T16:04:29.959572Z",
     "shell.execute_reply": "2025-05-31T16:04:29.958984Z",
     "shell.execute_reply.started": "2025-05-31T16:04:02.587809Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply RF model\n",
    "tss_map_depois = apply_rf_model(rrs_data_depois, valid_mask_depois, spatial_info_depois)\n",
    "\n",
    "# Save the image\n",
    "save_tss_map(tss_map_depois, spatial_info_depois, \"Outputs/tss_depois.tif\")\n",
    "\n",
    "# Plot results\n",
    "plot_tss_map(tss_map_depois, \"TSS Depois\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacfe55a-e86f-4db2-a522-b222661492f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Geospatial)",
   "language": "python",
   "name": "geospatial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
